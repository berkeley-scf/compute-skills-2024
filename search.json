[
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "This work is licensed under a Creative Commons Attribution 4.0 International License.",
    "crumbs": [
      "License"
    ]
  },
  {
    "objectID": "prep.html",
    "href": "prep.html",
    "title": "Using DataHub as a commmon computational environment",
    "section": "",
    "text": "While in principle, it’s fine to use your laptop, it will be hard for us to diagnose all the different problems that might arise with so many participants. So we recommend using a common computational environment during the workshop. We’ll use the Berkeley DataHub for this. You can think of DataHub as providing user-specific virtual machines with identical software for all of us to use.\nThe exception is that if you already have experience using your laptop with the shell/terminal, Git (and pushing to GitHub) and Python.\nClick here to access your own machine/server with Python, git, and terminal access on the campus DataHub (also used for various data science, CS, and statistics courses). (Do NOT go directly to datahub.berkeley.edu the first time you are accessing DataHub. If you do, you won’t have the repository materials available in your virtual machine.)\nThat will get you onto your server with the materials for the course, from the berkeley-scf/compute-skills-2024 repository available on the server.",
    "crumbs": [
      "Computational Environment"
    ]
  },
  {
    "objectID": "prep.html#check-your-environment",
    "href": "prep.html#check-your-environment",
    "title": "Using DataHub as a commmon computational environment",
    "section": "Check your environment",
    "text": "Check your environment\nTo check things look good:\n\nClick on Terminal (in the 3rd row of the Launcher tab, under Other). (If you have trouble finding the Terminal, go to File -&gt; New -&gt; Terminal.)\nCheck that your working directory is ~/compute-skills-2024 (by looking at the terminal prompt or running pwd)\nRun ls to see the files in the repository.",
    "crumbs": [
      "Computational Environment"
    ]
  },
  {
    "objectID": "prep.html#editing-files",
    "href": "prep.html#editing-files",
    "title": "Using DataHub as a commmon computational environment",
    "section": "Editing files",
    "text": "Editing files\nYou can combine text and code in a notebook, which you can start with:\n\nNew Launcher -&gt; Notebook -&gt; Python 3 (ipykernel), or\nFile -&gt; New -&gt; Notebook\n\nTo run the code in a cell, a shortcut is Ctrl + Enter/Return.\nTo create a script file containing just code, do File -&gt; New -&gt; Python file.",
    "crumbs": [
      "Computational Environment"
    ]
  },
  {
    "objectID": "prep.html#stopping-your-server",
    "href": "prep.html#stopping-your-server",
    "title": "Using DataHub as a commmon computational environment",
    "section": "Stopping your server",
    "text": "Stopping your server\nYou can stop your server via File-&gt; Hub Control Panel -&gt; Stop My Server.\nIf you only log out, any ongoing computations will still run in the background.",
    "crumbs": [
      "Computational Environment"
    ]
  },
  {
    "objectID": "units/solutions-computing.html",
    "href": "units/solutions-computing.html",
    "title": "SOLUTIONS: Introduction to Computing and the Command Line (optional)",
    "section": "",
    "text": "Exercise 1\n\n\n\nWhere is gzip installed on the system? What are some other commands/executables that are installed in the same directory?\n\n\n\n\n\n\n\n\nExercise 1 solution\n\n\n\n\n\ntype gzip\n\nls /usr/bin\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nTry to run the following command mkdir ~/projects/drought. It will fail. Look in the help information on mkdir to figure out how to make it work without first creating the projects directory.\n\n\n\n\n\n\n\n\nExercise 2 solution\n\n\n\n\n\nmkdir -p ~/projects/drought\n\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\nFigure out how to list out the files in a directory in order of decreasing file size, as a way to see easily what the big files are that are taking up the most space. Modify this command to get the result in the ascending order.\n\n\n\n\n\n\n\n\nExercise 3 solution\n\n\n\n\n\nls -lS\nls -lSr\n\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\nFigure out how to copy an entire directory and have the timestamps of the files retained rather than having the timestamps be the time that you copied the files.\nSee if you can combine the short form of an option with the long form of a different option.\nWhat happens if you use a single dash with the long form of an option. Are you able to interpret the error message?\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\n\n\ncp -pr mytoy mytoy_copy             # short form\ncp --recursive -p mytoy mytoy_copy  # long form plus short form\ncp -recursive -p mytoy mytoy_copy   # incorrect long form\ncp -r -e -c -u -r -s -i -v -e -p mytoy mytoy_copy"
  },
  {
    "objectID": "units/intro-python.html",
    "href": "units/intro-python.html",
    "title": "Introduction to Python (optional)",
    "section": "",
    "text": "Overview\n\n\n\nThis module introduces you to Python, making heavy use of this Software Carpentry lesson.",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/intro-python.html#python-fundamentals",
    "href": "units/intro-python.html#python-fundamentals",
    "title": "Introduction to Python (optional)",
    "section": "1. Python Fundamentals",
    "text": "1. Python Fundamentals\nWe’ll work through the Python Fundamentals section of the Software Carpentry workshop. The primary ideas covered are variables, data types, and basic function usage.\n\n\n\n\n\n\nExercise 1\n\n\n\nUsing the section on “Built-in Types” from the official “The Python Standard Library” reference, figure out how to compute:\n\n\\(\\sqrt{-1}\\)\n\n\\(\\exp(1.5)\\)\n\\((\\lceil \\frac{3}{4} \\rceil \\times 4)^3\\).\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nIs 1.0 of the integer type? What about 1? Is the result of 5/3 - 2/3 of the integer type? Is the mathematical value seen in Python an integer?\nHere’s a numerical puzzle. Why does the last computation not work, when the others do? And, for those of you coming from R, which of these computations don’t work in R?\n\n\nCode\n100000**10\n100000.0**10\n100000**100\n100000.0**100",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/intro-python.html#analyzing-patient-data",
    "href": "units/intro-python.html#analyzing-patient-data",
    "title": "Introduction to Python (optional)",
    "section": "2. Analyzing Patient Data",
    "text": "2. Analyzing Patient Data\nWe’ll work through the Analyzing Patient Data section of the Software Carpentry workshop. The primary ideas covered are libraries (aka packages), numpy arrays, and slicing.\n\n\n\n\n\n\nExercise 1\n\n\n\nWork on the questions about slicing in the section.\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nNote that ? and ?? only work in IPython (or a Jupyter notebook). For help in plain Python, use help(np.ndim).\n\nWhat happens if you type np.ndim?? (i.e., use two question marks)? What additional do you see compared to np.ndim??\nWhat does np.ndim() do? How does it execute under the hood? Consider why the following uses of ndim both work.\n\n\nCode\na = np.array([0, 1, 2])\na.ndim\nnp.ndim(a)\n\n\nNow explain why only one of these works.\n\n\nCode\na = [0, 1, 2]\na.ndim\nnp.ndim(a)\n\n\nType np.array? in a Notebook or at the IPython prompt. Briefly skim the docstring. nparray allows you to construct numpy arrays.\nType np. followed by the &lt;Tab&gt; key in a Notebook or at the IPython prompt. Choose two or three of the completions and use ? to view their docstrings. In particular, pay attention to the examples provided near the end of the docstring and see whether you can figure out how you might use this functionality.",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/intro-python.html#visualizing-tabular-data",
    "href": "units/intro-python.html#visualizing-tabular-data",
    "title": "Introduction to Python (optional)",
    "section": "3. Visualizing Tabular Data",
    "text": "3. Visualizing Tabular Data\nWe’ll work through the Visualizing Tabular Data section of the Software Carpentry workshop. The primary ideas covered are making basic plots using the matplotlib package.\nSidenote: For the plots to show in a Jupyter Notebook, it seems that we need all the code for creating a given plot to be in a single cell.\n\n\n\n\n\n\nExercise\n\n\n\nUsing the following code, read in the GapMinder data using Pandas (to be discussed later) and run the following code to make the variables easily available (you don’t need to know anything about Pandas).\nDo this in a Jupyter notebook so that it’s easy to see the plots.\n\n\nCode\nimport numpy as np\nimport pandas as pd\ndat = pd.read_csv('gapminder.csv')\nlifeExp = np.array(dat.lifeExp)\ngdpPercap = np.array(dat.gdpPercap)\nyear = np.array(dat.year)\n\n## Hint: slicing using an array of booleans\n## gdpPercap[year &gt; 2010]\n\n\n\nMake a scatterplot of lifeExp vs gdpPerCap for 2007.\nConsider whether plotting income on a logarithmic axis is a better way to display the data.\nUsing at least two years, make an array of plots (in one figure) where each subplot is a different year.\nAdd nice axis labels and titles.",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/intro-python.html#storing-multiple-values-in-lists",
    "href": "units/intro-python.html#storing-multiple-values-in-lists",
    "title": "Introduction to Python (optional)",
    "section": "4. Storing Multiple Values in Lists",
    "text": "4. Storing Multiple Values in Lists\nWe’ll work through the Storing Multiple Values in Lists section of the Software Carpentry workshop. The primary ideas covered are creating, extracting from, and manipulating lists.\n\n\n\n\n\n\nExercise 1\n\n\n\nCreate a list of numbers, called x1. Reverse the order of the items in the list using slicing. Now reverse the order of the items using a list method. How does using the method differ from slicing? Hint: you can type x. followed by the &lt;Tab&gt; key in a Notebook or at the IPython prompt to find the various methods that can be applied to a list.\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nFigure out some different ways of combining your list of numbers with a list of strings to create a single list of mixed type elements. (Hint: you can type x. followed by the &lt;Tab&gt; key in a Notebook or at the IPython prompt to find the various methods that can be applied to a list.)\nNow try to sort the resulting list. What happens?\n\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\nAnswer the question related to Overloading in the Software Carpentry section.\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\nWhat does the following tell you about copying and use of memory in lists in Python?\n\n\nCode\na = [1, 3, 5]\nb = a\nid(a)\nid(b)\n# this should confirm what you might suspect\na[1] = 5",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/intro-python.html#repeating-actions-with-loops",
    "href": "units/intro-python.html#repeating-actions-with-loops",
    "title": "Introduction to Python (optional)",
    "section": "5. Repeating Actions with Loops",
    "text": "5. Repeating Actions with Loops\nWe’ll work through the Repeating Actions with Loops section of the Software Carpentry workshop. The primary ideas covered relate to using for loops to automate operations.\nIn addition to the explicit for looping shown in the unit, Python also has a construct called list comprehension to do something similar. Note that some people really dislike the list comprehension syntax as being hard to read.\n\n\nCode\nvals = [0, 5, 7]\nvals_times2 = [val*2 for val in vals]\nvals_times2\n\n\n[0, 10, 14]\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nSee what [1, 2, 3] + 3 returns. Try to explain what happened and why.\nHow would you do the same task using a for loop? The range function may be helpful as might the enumerate function.\nUse list comprehension to perform the same element-wise addition of the scalar to the list of scalars.\nChange [1, 2, 3] to be a numpy array and then add three using + 3.",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/intro-python.html#making-choices",
    "href": "units/intro-python.html#making-choices",
    "title": "Introduction to Python (optional)",
    "section": "7. Making Choices",
    "text": "7. Making Choices\nWe’ll work through the Making Choices section of the Software Carpentry workshop. The primary ideas covered are using conditionals (if-then-else statements) and boolean (logical) operations.\n\n\n\n\n\n\nExercise 1\n\n\n\nAnswer this question from the Software Carpentry section.\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nAnswer this question from the Software Carpentry section.",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/intro-python.html#creating-functions",
    "href": "units/intro-python.html#creating-functions",
    "title": "Introduction to Python (optional)",
    "section": "8. Creating Functions",
    "text": "8. Creating Functions\nWe’ll work through the Creating Functions section of the Software Carpentry workshop. The primary ideas covered are defining, using, testing, and debugging functions.\nWe’ll skip over testing and documentation as we’ll cover those in depth later this week (and definitely NOT because they are unimportant).\nExercises\n\n\n\n\n\n\nExercise 1\n\n\n\nDefine a function called sqrt that will take the square root of a number and will (if requested by the user) set the square root of a negative number to 0.\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nWhat happens if you modify a list within a function in Python; why do you think this is?\nWhat happens if you modify a single number (scalar) within a function in Python; why do you think this is?\n\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\nAnswer the question related to local vs. global variables in the Software Carpentry section.",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/intro-python.html#errors-and-exceptions",
    "href": "units/intro-python.html#errors-and-exceptions",
    "title": "Introduction to Python (optional)",
    "section": "9. Errors and Exceptions",
    "text": "9. Errors and Exceptions\nWe’ll work through the Errors and Exceptions section of the Software Carpentry workshop. The primary ideas covered relate to understanding error messages and tracebacks. In the Computational Tools and Practices session, we’ll talk about writing your own code that handles errors.\n\n\n\n\n\n\nExercise 1\n\n\n\nAnswer this question from the Software Carpentry section.\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nAnswer these questions from Sofware Carpentry:\n\nSyntax errors\nName errors\nIndex errors",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/intro-python.html#extra-part-1.-some-other-useful-data-structures",
    "href": "units/intro-python.html#extra-part-1.-some-other-useful-data-structures",
    "title": "Introduction to Python (optional)",
    "section": "EXTRA Part 1. Some other useful data structures",
    "text": "EXTRA Part 1. Some other useful data structures\n\nTuples\nTuples are immutable sequences of (zero or more) objects. Functions in Python often return tuples.\n\n\nCode\nx = 1; y = 'foo'\n\nxy = (x, y)\ntype(xy)\nxy = x,y\ntype(xy)\n\nxy\nxy[1]\n\nxy[1] = 3   immutable!\n\n\n\n  Cell In[3], line 11\n    xy[1] = 3   immutable!\n                ^\nSyntaxError: invalid syntax\n\n\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\n\nWhat’s weird about this? What are the types involved?\n\n\nCode\nz = x,y\na,b = x,y\n\n\nCreate the following: x=5 and y=99. Now swap their values using a single line of code. (For R users, how would you do this in R?)\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nWhat happens when you multiply a tuple by a number?\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\nWhy do you think there is no reverse method for tuples?\nWhat’s nice about using immutable objects in your code?\n\n\n\n\n\nDictionaries\nDictionaries are mutable, unordered collections of key-value pairs. They’re a very important data structure in Python so I’m surprised they weren’t discussed in the Software Carpentry sections.\n\n\nCode\nstudents = {\"Francis Bacon\": ['A', 'B+', 'A-'], \n            \"Marie Curie\": ['A-', 'A-'], \n            \"Aristotle\": 'and now for something completely different'}\nstudents\nstudents.keys()\nstudents.values()\nstudents[\"Marie Curie\"]\nstudents[\"Marie Curie\"][1]\n\n\n'A-'\n\n\n\n\nCode\nstudents.\n\n\nstudents.clear(       students.items(       students.setdefault(\nstudents.copy(        students.keys(        students.update(\nstudents.fromkeys(    students.pop(         students.values(\nstudents.get(         students.popitem()    \n\n\n\n\n\n\nExercise 4\n\n\n\nHow can you add an item to a dictionary?\n\n\n\n\n\n\n\n\nExercise 5\n\n\n\nHow do you combine two dictionaries into a single dictionary?\n\n\n\n\n\n\n\n\nExercise 6 (for R users)\n\n\n\n\nWhat are some analogs to dictionaries in R?\nHow are dictionaries different from such analogous structures in R?",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/intro-python.html#extra-part-2-a-bit-on-numpy-scipy-and-pandas",
    "href": "units/intro-python.html#extra-part-2-a-bit-on-numpy-scipy-and-pandas",
    "title": "Introduction to Python (optional)",
    "section": "EXTRA Part 2: A bit on numpy, scipy and pandas",
    "text": "EXTRA Part 2: A bit on numpy, scipy and pandas\n\nNumpy and scipy\nStandard lists in Python are not amenable to mathematical manipulation, unlike standard vectors in R. Instead we generally work with numpy arrays. These arrays can be of various dimensions (i.e., vectors, matrices, multi-dimensional arrays).\n\n\nCode\nimport numpy as np\nz = [0, 1, 2] \n\ny = np.array(z)\ny*3\n\ny.dtype\n\n\nx = np.array([[1, 2], [3, 4]], dtype=np.float64)\nx*x\nx.dot(x)\nx.T\n\nnp.linalg.svd(x)\n\ne = np.linalg.eig(x)\n\ne[0]  # first eigenvalue (not the largest in this case...)\ne[1][:, 0] # corresponding eigenvector\n\n\narray([-0.82456484,  0.56576746])\n\n\nAll of the elements of the array must be of the same type.\nThere are a variety of numpy functions that allow us to do standard mathematical/statistical manipulations.\nHere we’ll use some of those functions in addition to some syntax for subsetting and vectorized calculations.\n\n\nCode\nnp.linspace(0, 1, 5)\n\nnp.random.seed(0)\nx = np.random.normal(size=10)\n\npos = x &gt; 0\n\ny = x[pos]\n\nx[[1, 3, 4]]\n\nx[pos] = 0\n\nnp.cos(x)\n\n\narray([1.        , 1.        , 1.        , 1.        , 1.        ,\n       0.55928119, 1.        , 0.98856735, 0.99467766, 1.        ])\n\n\nscipy has even more numerical routines, including working with distributions and additional linear algebra.\n\n\nCode\nimport scipy.stats as st\nst.norm.cdf(1.96, 0, 1)\nst.norm.cdf(1.96, 0.5, 2)\nst.norm(0.5, 2).cdf(1.96)\n\n\n\n\nPandas\nPandas provides a Python implementation of R’s dataframe capabilities. Let’s see some example code.\n\n\nCode\nimport pandas as pd\ndat = pd.read_csv('gapminder.csv')\ndat.head()\n\ndat.columns\ndat['year']\ndat.year\ndat[0:5]\n\ndat.sort_values(['year', 'country'])\n\ndat.loc[0:5, ['year', 'country']]  # R-style indexing\n\ndat[dat.year == 1952]\n\nndat = dat[['pop','lifeExp','gdpPercap']]\nndat.apply(lambda col: col.max() - col.min())\n\n\npop          1.318623e+09\nlifeExp      5.900400e+01\ngdpPercap    1.132820e+05\ndtype: float64\n\n\nNow let’s see the sort of split-apply-combine functionality that is popular in dplyr and related R packages.\n\n\nCode\ndat2007 = dat[dat.year == 2007].copy()  \n\ndat2007.groupby('continent', as_index=False)[['lifeExp','gdpPercap']].mean()\n\ndef stdize(vals):\n    return((vals - vals.mean()) / vals.std())\n\ndat2007['lifeExpZ'] = dat2007.groupby('continent')['lifeExp'].transform(stdize)",
    "crumbs": [
      "Modules",
      "Intro to Python (optional)"
    ]
  },
  {
    "objectID": "units/point-to-prep.html",
    "href": "units/point-to-prep.html",
    "title": "Preparation",
    "section": "",
    "text": "Preparation\nOur primary computing context will be the UC Berkeley DataHub. This provides us with a common platform on which we are assured to get the same behavior as each other, allowing us to use the command line/shell/terminal and Python, including Jupyter notebooks. In particular getting a common command line environment would be hard otherwise.\n\n\n\n\n\n\nUsing your own laptop (optional)\n\n\n\n\n\nIf you haven’t already used the shell/terminal and Python on your laptop, we recommend you use the DataHub so that we don’t have to troubleshoot problems on multiple laptops.\nIf you do use your laptop, you’ll need Python installed, for which we recommend using Miniforge. Another option is the Anaconda distribution of Python](https://www.anaconda.com/distribution)\nFor the shell/terminal parts of this material, you can use the Terminal on your Mac, but not on Windows.\nIf you do use your own laptop, you’ll need to clone this GitHub repository. If you don’t know how to do that, just download this zip file and unzip it into your home directory on your computer."
  },
  {
    "objectID": "units/comp-practices.html",
    "href": "units/comp-practices.html",
    "title": "Version control, programming, and testing",
    "section": "",
    "text": "Overview\n\n\n\nThis module presents the core content of the workshop on version control (using Git), code style, documentation, and testing.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#newtons-method-background",
    "href": "units/comp-practices.html#newtons-method-background",
    "title": "Version control, programming, and testing",
    "section": "Newton’s method background",
    "text": "Newton’s method background\nWe’ll use a running example, Newton’s method for optimization, during this workshop. It’s simple enough to be straightforward to code but can involve various modifications, extensions, etc. to be a rich enough example that we can use it to demonstrate various topics and tools.\nRecall that Newton’s method works as follows to optimize some objective function, \\(f(x)\\), as a function of univariate or multivariate \\(x\\), where \\(f(x)\\) is univariate.\nNewton’s method is iterative. If we are at step \\(t-1\\), the next value (when minimizing a function) is:\n\\[\nx_t = x_{t-1} - f^{\\prime}(x_{t-1}) / f^{\\prime\\prime}(x_{t-1})\n\\]\nHere are the steps:\n\ndetermine a starting value, \\(x_0\\)\niterate:\n\nat step \\(t\\), the next value (the update) is given by the equation above\nstop when \\(\\left\\Vert x_{t} - x_{t-1} \\right\\Vert\\) is “small”\n\n\nYou can derive it by finding the root of the gradient function using a Taylor series approximation to the gradient.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-implement-univariate-newtons-method",
    "href": "units/comp-practices.html#exercise-implement-univariate-newtons-method",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Implement univariate Newton’s method",
    "text": "Exercise: Implement univariate Newton’s method\nHere’s what you’ll need your code to do:\n\naccept a starting value, \\(x_0\\), and the function, \\(f(\\cdot)\\), to optimize\nimplement the iterative algorithm\nimplement the stopping criterion (feel free to keep this simple)\ncalculate the first and second derivatives using a basic finite difference approach to estimating the derivative based on the definition of a derivative as a limit\n\nnote that the second derivative can be seen as calling the first derivative twice…\n\nconsider what to return as the output (feel free to keep it simple)\ndon’t worry much for now about making your code robust or dealing with tricky situations\n\n\n\n\n\n\n\nWarning\n\n\n\nDon’t make your finite difference (“epsilon”) too small or you’ll actually get inaccurate estimates. (We’ll discuss why when we talk a bit out numerical issues in computing later.)\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor now, please do not use any Python packages that provide finite difference-based derivatives (we’ll do that later, and it’s helpful to have more code available for the work we’ll do today).\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou’re welcome to develop your code in a Notebook or in the DataHub editor or in a separate editor on your laptop.\n\n\nOnce you’ve written your Python functions, put your code into a simple text file, called newton.py. In doing so you’ve created a Python module. Once you have your module, you can use it like this:\n\n\nCode\nimport newton\nimport numpy as np\nnewton.optimize(start, fun)   ## Assuming your function is called `optimize`.\nnewton.optimize(2.5, np.cos)  ## Minimizing cos(x) from close-ish to one minimum.\n\n\nA module is a collection of related code in a file with the extension .py. The code can include functions, classes, and variables, as well as runnable code. To access the objects in the module, you need to import the module.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-creating-a-git-repository-on-github",
    "href": "units/comp-practices.html#exercise-creating-a-git-repository-on-github",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Creating a Git repository (on GitHub)",
    "text": "Exercise: Creating a Git repository (on GitHub)\nGo to github.com/&lt;your_username&gt; and click on the Repositories tag. Then click on the New button.\n\nIn the form, give the repository the name newton-practice (so others who are working with you can find it easily)\nProvide a short description\nClick on “Add a README file”.\nLeave the repository as “Public” so that others can interact with your repository when we practice later.\nScroll down to Python under Add .gitignore.\nSelect a license (the BSD 3 Clause license is a good “permissive” one).\n\n\n\n\n\n\n\nCreating repositories on your laptop first\n\n\n\nIt’s also possible to create the repository from the terminal on your machine and then link it to your GitHub account, but that’s a couple extra steps we won’t go into here at the moment.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-accessing-github-repositories-from-datahub",
    "href": "units/comp-practices.html#exercise-accessing-github-repositories-from-datahub",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Accessing GitHub repositories from DataHub",
    "text": "Exercise: Accessing GitHub repositories from DataHub\nAuthenticating with GitHub can be a bit tricky, particularly when using DataHub (i.e., JupyterHub).\nPlease follow these instructions.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#basic-use-of-a-repository",
    "href": "units/comp-practices.html#basic-use-of-a-repository",
    "title": "Version control, programming, and testing",
    "section": "Basic use of a repository",
    "text": "Basic use of a repository\nIn the terminal, let’s make a small change to the README, register the change with Git (this is called a commit), and push the changes upstream to GitHub (which has the remote copy of the repository).\n\nStep 1. Clone the repository\nFirst make a local copy of the repository from the remote on GitHub. It’s best do this outside of the compute-skills-2024 directory; otherwise you’ll have a repository nested within a repository.\ncd  # Avoid cloning into the `compute-skills-2024` repository.\ngit clone https://github.com/&lt;your_username&gt;/newton-practice\nIf we run this:\ncd newton-practice\nls -l .git\ncat .git/config\nwe should see a bunch of output (truncated here) indicating that newton-practice is a Git repository, and that in this case the local repository is linked to a remote repository (the repository we created on GitHub):\ntotal 40\n-rw-r--r-- 1 jovyan jovyan  264 Aug  2 15:04 config\n-rw-r--r-- 1 jovyan jovyan   73 Aug  2 15:04 description\n-rw-r--r-- 1 jovyan jovyan   21 Aug  2 15:04 HEAD\n-rw-r--r--   1 paciorek scfstaff   16 Jul 24 14:48 COMMIT_EDITMSG\n-rw-r--r--   1 paciorek scfstaff  656 Jul 23 18:20 config\n&lt;snip&gt;\n\n&lt;snip&gt;\n[remote \"origin\"]\n        url = https://github.com/paciorek/newton-practice\n        fetch = +refs/heads/*:refs/remotes/origin/*\n&lt;snip&gt;\nStep 2. Add files\nNext move (or copy) your Python module into the repository directory. For the demo, I’ll use a version of the Newton code that I wrote that has some bugs in it (for later debugging). The file is not in the repository.\ncd newton-practice\ncp ../compute-skills-2024/units/newton-buggy.py newton.py\n## Tell git to track the file\ngit add newton.py\nStep 3. Edit file(s)\nEdit the README file to indicate that the repository has a basic implementation of Newton’s method. (In DataHub, you can double-click on the README in the file manager pane.)\ngit status\n## Tell git to keep track of the changes to the file.\ngit add README.md\ngit status\n## Register the changes with Git.\ngit commit -m\"Add basic implementation of Newton's method.\"\ngit status\n## Synchronize the changes with the remote.\ngit push\n\n\n\n\n\n\nNote\n\n\n\nWe could have cloned the (public) repository without the gh_scoped_creds credentials stuff earlier, but if we tried to push to it, we would have been faced with GitHub asking for our password, which would have required us to create a GitHub authentication token that we would paste in.\n\n\n\n\n\n\n\n\nNote\n\n\n\nInstead of having to add files that already part of the repository (such as README.md) we could do:\ngit commit -a -m\"Update README.\"\nWe do need to explicitly add any new files (e.g., newton.py) that are not yet registered with git via git add.\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can also edit and add files directly to your GitHub repository in a browser window. This is a good backup if you run into problems making commits from DataHub or your laptop.\n\n\n\n\nWriting good commit messages\nSome tips:\n\nConcisely describe what changed (and for more complicated situations, why), not how.\nTwo options (depending on whether the commit makes one or more changes):\n\nKeep it short (one line, &lt;72 characters)\nHave a subject line separated from the body by a blank line.\n\nKeep subject to 50 characters and each body line to 72 characters.\nBest to edit message in an editor – omit the -m flag to git commit.\n\n\nIf you’re working on a project with GitHub issues, reference the issue at the bottom.\nStart each item in the message with a verb (present tense) and provide a complete sentence.\n\nIf you find your commit message is covering multiple topics, it probably means you should have made multiple (“atomic”) commits.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-put-your-code-in-your-repository",
    "href": "units/comp-practices.html#exercise-put-your-code-in-your-repository",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Put your code in your repository",
    "text": "Exercise: Put your code in your repository\nAdd your new code to your repository. Then commit and push to GitHub.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-code-review",
    "href": "units/comp-practices.html#exercise-code-review",
    "title": "Version control, programming, and testing",
    "section": "Exercise: code review",
    "text": "Exercise: code review\n\nStep 1: Make suggestions\nGo to your partner’s repository at https://github.com/&lt;user_name&gt;/newton-practice.\n\nLook over their code.\nMake some comments/suggestions in a new GitHub issue (go to the Issues button and click on New issue).\n\n\n\nStep 2: Respond to suggestions\nIn response to your partner’s comments, make some small change(s) to your newton.py code.\nYou can do this in DataHub (or locally on your laptop if that’s what you’re doing) and make a commit as we did in the previous exercise.\nOr you can do the editing in your GitHub browser window by clicking on the file and choosing the pencil icon (far right) to edit it. When you save it, a commit will be made. Make sure to provide a commit message. You can also create new files via the + button in the top of the left sidebar. If you make changes directly on GitHub, you’ll also want to run git pull to pull down the changes to your local repository on DataHub or your laptop.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#git-visuals-understanding-git-concepts",
    "href": "units/comp-practices.html#git-visuals-understanding-git-concepts",
    "title": "Version control, programming, and testing",
    "section": "Git visuals: Understanding Git concepts",
    "text": "Git visuals: Understanding Git concepts\nFernando’s Statistics 159/259 materials have a nice visualization (online version, PDF version) of a basic Git workflow that we’ll walk through.\nNote that we haven’t actually seen in practice some of what is shown in the visual: tags, branches, and merging, but we’ll be using those ideas later.\nFernando’s lecture materials from Statistics 159/259 illustrate that the steps shown in the visualization correspond exactly to what ppens when running the Git commands from the command line.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#key-components-and-terminology",
    "href": "units/comp-practices.html#key-components-and-terminology",
    "title": "Version control, programming, and testing",
    "section": "Key components and terminology",
    "text": "Key components and terminology\n\nCommits\nA commit is a snapshot of our work at a point in time. So far in our own repository, we’ve been working with a linear sequence of snapshots, but the visualization showed that we can actually have a directed acyclic graph (DAG) of snapshots once we have branches.\nEach commit has:\n\na hash identifier - a unique identifier produced by hashing the changes introduced in the commit and also the parent commit,\nhashes of the files in the repository in their current state, and\nthe changes (based on the diff tool) relative to the parent commit.\n\n\n\n\nA Git commit (Credit: ProGit book, CC License)\n\n\nWe identify each node (commit) with a hash, a fingerprint of the content of each commit and its parent. It is important the fact that the hash include information of the parent node, since this allow us to keep the check the structural consistency of the DAG.\nWe can illustrate what Git is doing easily in Python.\nLet’s create a first hash:\n\n\nCode\nfrom hashlib import sha1\n\n# Our first commit\ndata1 = b'This is the start of my paper.'\nmeta1 = b'date: 1/1/17'\nhash1 = sha1(data1 + meta1).hexdigest( )\nprint('Hash:', hash1)\n\n\nHash: 3b32905baabd5ff22b3832c892078f78f5e5bd3b\n\n\n￼ Every small change we make on the previous text with result in a full change of the associated hash code. Notice also how in the next hash we have included the information of the parent node.\n\n\nCode\ndata2 = b'Some more text in my paper...'\nmeta2 = b'date: 1/2/1'\n# Note we add the parent hash here!\nhash2 = sha1(data2 + meta2 + hash1.encode()).hexdigest()\nprint('Hash:', hash2)\n\n\nHash: 1c12d2aad51d5fc33e5b83a03b8787dfadde92a4\n\n\n\n\nA repository\nA repository is the set of files for a project with their history. It’s a collection of commits in the form of an directed acyclic graph.\n\n\n\nA (simple) Git repository (Credit: ProGit book, CC License)\n\n\nSome other terms:\n\nHEAD: a pointer to the current commit\ntag: a label for a commit\nbranch: a commit - often indicating a commit that has “branched” off of some main workflow or some linear sequence of commits\n\n\n\nStaging area / index\nThe index (staging area) keeps track of changes (made to tracked files) that are added, but that are not yet committed.\n\n\n\nlocal operations in a repository (Credit: ProGit book, CC License)\n\n\n\n\n\n\n\n\nRolling back changes (optional)\n\n\n\n\nUncommitted changesStaged, uncommitted changesCommitted changesPushed changes\n\n\nIf I make some changes to a file that I decide are a mistaken, before git add (i.e., before registering/staging the changes with git), I can always still edit the file to undo the mistakes.\nBut I can also go back to the version stored by Git.\n# git checkout -- file.txt  # This is older syntax.\ngit restore file.txt\n\n\nIf we’ve added (staged) files via git add but have not yet committed them, the files are in the index (staging area). We can get those changes out of the staging area like this:\ngit status\n# git reset HEAD file.txt  # This is older syntax.\ngit restore --staged file.txt\ngit status\nNote that the changes still exist in file.txt but they’re no longer registered/staged with Git.\n\n\nSuppose you need to add or modify to your commit. This illustrates a few things you might do to update your commit.\ngit commit -m 'Initial commit'\ngit add forgotten_file.txt\n# Edit file.txt.\ngit add file.txt\n# Get version of file from previous commit.\ngit checkout &lt;commit_hash&gt; file.txt\ngit commit --amend\n\n\ngit revert &lt;commit_hash&gt;\ngit push\nNote that this creates a new commit that undoes the changes you don’t want. So the undoing shows up in the history. This is the safest option.\nIf you’re sure no one else has pulled your changes from the remote:\ngit reset &lt;commit_hash&gt;\n# Make changes\ngit commit -a -m'Rework the mistake.'\ngit push -f origin &lt;branch_name&gt;\nThis will remove the previous commit at the remote (GitHub in our case).",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#linting",
    "href": "units/comp-practices.html#linting",
    "title": "Version control, programming, and testing",
    "section": "Linting",
    "text": "Linting\nLinting is the process of applying a tool to your code to enforce style.\nWe’ll demo using ruff to some example code. You might also consider black.\nWe’ll practice with ruff with a small module we’ll use next also for debugging.\n\nFirst, we check for and fix syntax errors.\nruff check newton.py\nThen we ask ruff to reformat to conform to standard style.\ncp newton.py newton-save.py   # So we can see what `ruff did.\nruff format newton.py\n\nLet’s see what changed:\ndiff newton-save.py newton.py",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-add-documentation-and-comments-to-your-newton-module",
    "href": "units/comp-practices.html#exercise-add-documentation-and-comments-to-your-newton-module",
    "title": "Version control, programming, and testing",
    "section": "Exercise: add documentation and comments to your Newton module",
    "text": "Exercise: add documentation and comments to your Newton module\n\nAdd a doc string to each of your functions. Focus on your main function. Take a look at an example, such as help(numpy.linalg.cholesky) to see the different parts and the format.\nConsider whether to add comments to your code.\nApply ruff to your code.\nCompare the results with the style suggestions above and do additional reformatting as needed.\nCommit and push to GitHub. Remember to have a good commit message!",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#demo-debugging-my-newton-implementation",
    "href": "units/comp-practices.html#demo-debugging-my-newton-implementation",
    "title": "Version control, programming, and testing",
    "section": "Demo: debugging my Newton implementation",
    "text": "Demo: debugging my Newton implementation\n\nUsing the JupyterLab visual debugger\nLet’s debug my buggy implementation of Newton’s method.\n\n\nCode\nimport newton\nimport numpy as np\nnewton.optimize(2.95, np.cos)\n\n\nClearly that doesn’t work. Let’s debug it.\nWe’ll work in our Jupyter notebook.\n\nFirst turn on debugging capability by clicking on the small “bug” icon of the top navigation bar under the file tabs and to the left of the info about the kernel.\nNext we click on a line of code to set a breakpoint.\nNow we run the function by executing the cell containing the function call. We can:\n\ncontinue (to the end or the next breakpoint),\nfinish,\nrun the next line,\nstep (in/down) into a nested function\nstep (out/up) out of a function, or\nevaluate an expression (one needs to click on the “log” icon at the bottom to see the output).\n\n\nIf we want to debug into functions defined in files, we can add breakpoint() in the location in the file where we want the breakpoint and one should see the code in the SOURCE box in the debugger panel. So far, I’ve found this to be a bit hard to use, but that may well just be my inexperience with the JupyterLab debugger.\n\n\nUsing the IPython debugger (ipdb)\nWe can use the IPython %debug “magic” to activate a debugger as well.\nOne way this is particularly useful is “post-mortem” debugging, i.e., debugging when exceptions (errors) have occurred. We just invoke %debug and then (re)run the code that is failing. The ipdb debugger will be invoked when the error occurs.\nOnce in the ipdb debugger, we can use these commands (most of which correspond to icons we used to control the JupyterLab debugger behavior):\n\nc to continue execution (until the end or the next breakpoint)\nn to run the next line of code\nu and d to step up and down through the stack of function calls\np expr to print the result of the expr code\nq to quit the debugger\n\nWe’ll put a silly error into the code, restart the kernel, and use the post-mortem debugging approach as an illustration.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-debugging-your-newton-code",
    "href": "units/comp-practices.html#exercise-debugging-your-newton-code",
    "title": "Version control, programming, and testing",
    "section": "Exercise: debugging your Newton code",
    "text": "Exercise: debugging your Newton code\nRun your Newton method on the following function, \\(x^4/4 - x^3 -x\\), for various starting values. Sometimes it should fail.\nUse the debugger to try to see what goes wrong. (For our purposes here, do this using the debugger; don’t figure it out from first principles mathematically or graphically.)\nConditional breakpoints are a useful tool that causes the debugger to stop at a breakpoint only if some condition is true (e.g., if some extreme value is reached in the Newton iterations). I don’t see that it’s possible to do this with the JupyterLab debugger, but with the ipdb debugger you can do things like this to debug a particular line of a particular file if a condition (here x==5) is met:\nb path/to/script.py:999, x==5",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#demo-unit-tests-and-pytest",
    "href": "units/comp-practices.html#demo-unit-tests-and-pytest",
    "title": "Version control, programming, and testing",
    "section": "Demo: Unit tests and pytest",
    "text": "Demo: Unit tests and pytest\npytest is a very popular package/framework for testing.\nWe create test functions that check for the expected result.\nWe use assert statements. These are ways of generally setting up sanity checks in your code. They are usually used in development, or perhaps data analysis workflows, rather than production code. They are a core part of setting up tests such as here with pytest.\npytest test_newton.py",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-test-cases",
    "href": "units/comp-practices.html#exercise-test-cases",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Test cases",
    "text": "Exercise: Test cases\nWith a partner, brainstorm some test cases for your implementation of Newton’s method in terms of the user’s function and input values a user might provide.\nIn addition to cases where it should succeed, you’ll want to consider cases where Newton’s method fails and test whether the user gets an informative result. Of course as a starting point, the case we used for the debugging exercise is a good one for a failing case.\nWe’ll collect some possible tests once each group has had a chance to brainstorm.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-unit-tests",
    "href": "units/comp-practices.html#exercise-unit-tests",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Unit tests",
    "text": "Exercise: Unit tests\nImplement your test cases as unit tests using the pytest package.\nInclude tests for:\n\nsuccessful optimization\nunsuccessful optimization\ninvalid user inputs\n\nwith the expected output being what you want to happen, not necessarily what your function does.\nYou’ll want cases where you know the correct answer. Start simple.\n\n\n\n\n\n\nOnly write tests now\n\n\n\nFor now don’t modify your code even if you start to suspect how it might fail. Writing the tests and then modifying code so they pass is an example of test-driven development.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exceptions-in-python",
    "href": "units/comp-practices.html#exceptions-in-python",
    "title": "Version control, programming, and testing",
    "section": "Exceptions in Python",
    "text": "Exceptions in Python\nTo understand how Python handles error, you can take a look at the Errors and Exceptions section of the Software Carpentry workshop. The primary ideas covered are understanding error messages and tracebacks.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-error-trapping-robust-code-and-defensive-programming",
    "href": "units/comp-practices.html#exercise-error-trapping-robust-code-and-defensive-programming",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Error trapping, robust code, and defensive programming",
    "text": "Exercise: Error trapping, robust code, and defensive programming\nNow we’ll try to go beyond simply returning a failed result and see if we can trap problems early on and write more robust code.\nWork on the following improvements:\n\nCheck user inputs are valid.\nAdd warnings to the user if it seems that Newton’s method is taking a bad step.\nModify your function so that when it fails, the result is informative to the user.\n\nInclude a success/failure code (flag) in your output.\n\n\nYour code should handle errors using exceptions, as discussed earlier for Python itself. We don’t have time to go fully into how Python handles the wide variety of exceptions. But here are a few basic things you can do to raise an exception (i.e., to report an error and stop execution):\nif not callable(f):\n   raise TypeError(f\"Argument is not a function, it is of type {type(f)}\")\nif x &gt; 1e7:\n   raise RuntimeError(f\"At iteration {iter}, optimization appears to be diverging\")\nimport warnings\nif x &gt; 3:\n   warnings.warn(f\"{x} is greater than 3.\")\nNext, if you have time, consider robustifying your code if you have time:\n\nWhat might you do if the next step is worse than the current position?\n\nWhat might you do if the next step is outside the range of potential values (assuming a unimodal function)?",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#demo-branching-and-pull-requests-merge-conflicts",
    "href": "units/comp-practices.html#demo-branching-and-pull-requests-merge-conflicts",
    "title": "Version control, programming, and testing",
    "section": "Demo: Branching and pull requests, merge conflicts",
    "text": "Demo: Branching and pull requests, merge conflicts\nWe’ll demo the use of branching and PRs by fixing our optimize function.\n\nBranching\nFirst, let’s fix the error in our function in a new branch.\ngit switch -c fix_initial_bugs\nWe’ll now make the fixes and do the linting (not shown).\nPush the branch with the fix to GitHub.\ngit add newton.py\ngit commit -m'Fix initial bugs:\n- derivative interval too small\n- stopping criterion logic incorrect\n- copy-paste duplication'\ngit push -u origin fix_initial_bugs\n\n\nPull requests\nNow we’ll go to GitHub and start a pull request (PR).\nSince we’re the ones who control the repo, we’ll also review and merge in the PR.\n\n\nMerge conflicts\nNext let’s see a basic example of a merge conflict, which occurs when two commits modify (which could include deletion) the same line in a file. In this case Git requires the user to figure out what should be done.\nTo get an example, we need to create a conflict. I will add different documentation in the main and fix_initial_bugs branches. After pushing the main change, I’ll try to do a PR with the fix_initial_bugs.\nThe GitHub UI does a nice job of helping you resolve merge conflicts, as we’ll see.\n\n\n\n\n\n\nResolving conflicts at the command line\n\n\n\nYou can also get (and resolve) merge conflicts on the command line. Git will add some syntax to the conflicted file pointing out the conflicts that need to be resolved. Once you edit the conflicted file to fix the conflict, you can do git add &lt;name_of_file&gt; and then git commit.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#multivariate-newtons-method",
    "href": "units/comp-practices.html#multivariate-newtons-method",
    "title": "Version control, programming, and testing",
    "section": "Multivariate Newton’s method",
    "text": "Multivariate Newton’s method\nRecall that Newton’s method optimizes some objective function, \\(f(x)\\) as a function of univariate or multivariate \\(x\\), where \\(f(x)\\) is univariate.\nThe multivariate method extends the univariate, using the gradient (first derivative) vector and Hessian (second derivative) matrix.\nIf we are at step \\(t-1\\), the next value is:\n\\[\nx_{t+1}=x_{t}-H_{f}(x_{t})^{-1}\\nabla f(x_{t})\n\\]\nwhere \\(\\nabla f(x_{t}\\) is the gradient (first derivative with respect to each element of \\(x\\)) and \\(H_{f}(x_{t})\\) is the Hessian matrix (second derivatives with respect to all pairs of the elements of \\(x\\)).\nHere are the steps:\n\ndetermine a starting value, \\(x_0\\).\niterate:\n\nat step \\(t\\), the next value (the update) is given by the equation above\nstop when \\(\\left\\Vert x_{t} - x_{t-1} \\right\\Vert\\) is “small”",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-branching",
    "href": "units/comp-practices.html#exercise-branching",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Branching",
    "text": "Exercise: Branching\n\nMake sure you’ve committed your tests and any changes made to your univariate Newton’s method to your main branch. And make sure you push the changes to GitHub.\nMake a branch (called multivariate) in which you’ll implement the multivariate version of Newton’s method (see details above)\nImplement the algorithm, either in newton.py or in a new file if you prefer.\n\nYou may need to search online for how to calculate \\(H_{f}(x_{t})^{-1}\\nabla f(x_{t}\\).\nAt this point, if we think about calculating the Hessian it starts to feel more tedious to deal with the finite difference calculations, though it is a straightforward extension of what you already implemented. Feel free to look online to find a Python package that implements finite difference estimation of derivatives and use that in your code (see what Google indicates or if you use a ChatBot/LLM what they suggest).\nAs you are writing the code, you can continue to think about what might go wrong and include defensive programming tactics.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-pull-requests-prs",
    "href": "units/comp-practices.html#exercise-pull-requests-prs",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Pull requests (PRs)",
    "text": "Exercise: Pull requests (PRs)\nWhen you have your branch ready, make a pull request:\n\nMake a pull request into the remote for the repository by pushing the branch to GitHub\ngit push -u origin multivariate\nGo to GitHub to the Pull requests tab and make the PR, making a note of what the PR is about.\n\nDon’t (yet) merge in the PR. We want someone else to review it to have additional eyes on the code.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-code-review-1",
    "href": "units/comp-practices.html#exercise-code-review-1",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Code review",
    "text": "Exercise: Code review\nNow find a partner.\nGive the partner the URL for your repository on GitHub and ask them to look at the PR. In turn get the URL for their repository.\nIn reviewing the PR, make comments in the PR comment/conversation area on GitHub.\nIf you have time, explore these two additional options for making comments:\n\nReview changes:\n\nClick on the Files changed tab (or go to https://github.com/&lt;USERNAME&gt;/newton-practice/pull/&lt;PULL_ID&gt;/files for the specific “PULL_ID”).\nClick on the Review changes button.\n\nMake comments on specific lines\n\nClick on the Files changed tab (or go to https://github.com/&lt;USERNAME&gt;/newton-practice/pull/&lt;PULL_ID&gt;/files for the specific “PULL_ID”).\nHover over a specific line in a specific file with your mouse. A blue “plus” box should appear. Click on the plus to add a comment.\nClick on Add single comment or optionally experiment with Start a review.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/comp-practices.html#exercise-merge-the-pr",
    "href": "units/comp-practices.html#exercise-merge-the-pr",
    "title": "Version control, programming, and testing",
    "section": "Exercise: Merge the PR",
    "text": "Exercise: Merge the PR\nOnce you’ve seen the review by your partner:\n\nOn DataHub, make changes to the branch that was used in the pull request.\n\nAlternatively, you could make the changes directly on GitHub using its editing capabilities.\n\nOn DataHub, commit and push to GitHub.\nOn GitHub, merge in the (now revised) pull request and close the request.\n\nYou may want to delete the branch. This helps avoid having a profusion of unneeded branches.\n\nOn DataHub, run git pull to get the changes updated in the main branch of your local repository.\n\n\n\n\n\n\n\nThe full cycle of “git virtue”\n\n\n\nCongratulations. In the course of the day, you’ve worked through the steps of a complete, albeit small, project using an extensive set of concepts, skills, and tools used in real world projects.",
    "crumbs": [
      "Modules",
      "Computational Tools and Practices"
    ]
  },
  {
    "objectID": "units/mini-project.html",
    "href": "units/mini-project.html",
    "title": "(Optional) Python Mini-Project",
    "section": "",
    "text": "Background\nThe goal of the project is to analyze the tweeting behavior of the 100 US Senators in the US Senate. Each senator has a Twitter account and puts out tweets reflecting their thought and communicating with the people in the state they represent.\n(Note that these tweets were downloaded early in 2017, so they reflect tweeting just before President Obama stepped down and President Trump began his term.)\nThe goal of the project questions is to guide you through the steps of getting the data, processing and cleaning it, putting it in a format that makes it easier to analyze and then doing some basic analysis. The last few questions ask you to see if whether a senator mentions a president or presidential candidate depends on the party that the senator is part of. For example, do Democratic senators mention Barack Obama in their tweets more or less than Republican senators?\nFor background information only: This Python code downloads tweets using the Python twitter package to interact with Twitter’s API. You will only be able to run that code if you set up your own Twitter account and follow the instructions at the start of the file regarding filling in the authentication information (CONSUMER_KEY, CONSUMER_SECRET, etc.).\nI’ve already run the code mentioned above and downloaded the data for you. The downloaded information on the senators’ twitter accounts is in project/senators-list.json in the GitHub repository, while the downloaded tweets are in timelines.json. timelines.json is too big to put in the Github repository. You can find it at http://www.stat.berkeley.edu/~paciorek/transfer/timelines.json. Note that there are only 200 tweets for each senator because of limits on how many tweets can be accessed in a given request.\n\n\nQuestions\n\nLoad the senators-list.json and timelines.json files into Python as objects called senators and timelines, using this syntax:\n\n\nCode\nwith open(\"tmp.json\") as infile:\n     y = json.load(infile)\n\n\nWhat type of datastructure is timelines? How many timelines are there? What does each timeline correspond to?\nMake a list of the number of followers each senator has.\nWhat is the screen name of the senator with the largest number of followers.\nMake a list of lists where the outer list represents senators and the inner list contains the text of each senator’s tweets, and call it tweets.\nWrite a function, called remove_punct, that takes a word and returns the word with all punctuation characters removed, except for those that occur within a word.\nWrite a function that takes tweet and returns a cleaned up version of the tweet. Here is an example function to get you started:\n\n\nCode\ndef clean(tweet):\n    cleaned_words = [word.lower() for word in tweet.split() if\n                 'http' not in word and\n                  word.isalpha() and\n                  word != 'RT']\n    return ' '.join(cleaned_words)\n\nclean(tweets[0][0])\n\n\nNote that the function I’ve provided is a bit buggy - it has some problems with some tweets. If your goal is to convert the tweet into a discrete set of words, what is going wrong here? Fix up and extend the example function.\nUse the following file to create a list, called stopwords, that contains common english words: http://www.textfixer.com/resources/common-english-words.txt. Make sure to pull the data into Python by writing Python code to download and suck the data into Python.\nWrite a function, called tokenize, which takes a tweet, cleans it, and removes all punctuation and stopwords.\nCreate a list of lists, tweets_content, using your tokenize function.\nCreate a list, tokens, where all 200 of each senator’s tweets are made into a single string. Hint: this syntax might be useful: \" \".join(my_list_of_strings).\nCreate a Pandas dataFrame with the following columns: senator name or handle, party of the senator, and number of times a prominent politician is mentioned in each senator’s tweets. You might count the number of ‘Obama’, ‘Trump’, or ‘Clinton’ references.\nYou can use this to create the party column (1=Republican, 0=Democratic):\n\n\nCode\nparty = np.array([1,1,1,1,1,1,0,0,1,0,1,1,0,0,0,1,1,1,0,0,0,1,1,1,1,0,1,0,\n1,1,1,0,0,0,0,0,0,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,0,1,\n1,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,1,1,0,0,1,0,1,0,0,1,1,1,0,1])\n\n\nThat should correspond to the ordering in timelines but of course it would be more robust to create a dataFrame that has user names and party as columns and merge that with the count information.\nUse a Poisson GLM to assess the relationship between party and number of Obama/Trump/Clinton mentions. Does one party tend to mention Obama/Trump/Clinton more in their tweets? Can you deduce a pattern by considering the party of the senator and the party of Obama/Trump/Clinton?\nHere’s some syntax to help you get started:\n\n\nCode\nimport statsmodels.api as sm\nmodel = sm.GLM(endog = .,  exog = ., family = sm.families.Poisson())\nmodel.fit()\n\n\nDoes the statistical result make sense in light of the number of total mentions of Obama/Trump/Clinton by Republicans and the number of total mentions by Democrats?\nUse matplotlib to make histograms of the number of Obama mentions by senator, stratified by party.\nIs this consistent with the results of your statistical analysis?",
    "crumbs": [
      "Modules",
      "Python Mini Project (optional)"
    ]
  },
  {
    "objectID": "units/intro-computing.html",
    "href": "units/intro-computing.html",
    "title": "Introduction to Computing and the Command Line (optional)",
    "section": "",
    "text": "Overview\n\n\n\nThis module introduces you to some computing concepts and provides a brief tutorial on working on the command line (also known as, the shell, or the terminal).",
    "crumbs": [
      "Modules",
      "Intro to Computing and Command Line (optional)"
    ]
  },
  {
    "objectID": "units/intro-computing.html#basic-parallelization-example",
    "href": "units/intro-computing.html#basic-parallelization-example",
    "title": "Introduction to Computing and the Command Line (optional)",
    "section": "Basic parallelization example",
    "text": "Basic parallelization example\nAs an example, suppose we were carrying out 20-fold cross-validation and we were using a laptop with 4 cores.\nWe would generally use 4 workers (4 processes) to carry out the 20 tasks (each task being to fit the model on the non-held out data and make predictions on the held-out data in the fold). So 4 of the tasks could be executing at the same time. When a process finishes a task assigned to it, it can start on the next task that is still left to be done.",
    "crumbs": [
      "Modules",
      "Intro to Computing and Command Line (optional)"
    ]
  },
  {
    "objectID": "units/intro-computing.html#files-and-directories",
    "href": "units/intro-computing.html#files-and-directories",
    "title": "Introduction to Computing and the Command Line (optional)",
    "section": "Files and directories",
    "text": "Files and directories\n\nMoving around and listing information\nWe’ll start by thinking about the filesystem, which organizes our information/data into files on the computer’s disk.\nAnytime you are at the UNIX command line, you have a working directory, which is your current location in the file system.\nHere’s how you can see where you are using the pwd (“print working directory”) command:\n$ pwd\n/home/jovyan/compute-skills-2024\nand here’s how you use ls to list the files (and subdirectories) in the working directory…\n$ ls\nassets       license.qmd  README.md     units           _variables.yml\nbuttons.yml  prep.qmd     schedule.yml  Untitled.ipynb\nindex.qmd    _quarto.yml  syllabus.qmd  untitled.py\nNow suppose I want to be in a different directory so I can see what is there or do things to the files in that directory.\nThe command you need is cd (“change directory”) and an important concept you need to become familiar with is the notion of ‘relative’ versus ‘absolute’ path. A path is the set of nested directories that specify a location of interest on the filesystem.\nNow let’s go into a subdirectory. We can use cd with the name of the subdirectory. The subdirectory is found ‘relative’ to our working directory, i.e., found from where we currently are.\n$ cd units\n$ pwd\n/home/jovyan/compute-skills-2024/units\nWe could also navigate through nested subdirectories. For example, after going back to our home directory (using cd alone will do this), let’s go to the units subdirectory of the compute-skills-2024 subdirectory. The / is a separate character that distinguishes the nested subdirectories.\n$ cd\n$ cd compute-skills-2024/units\nYou can access the parent directory of any directory using ..:\n$ cd ..\n$ pwd\n/home/jovyan/compute-skills-2024\nWe can get more complicated in our use of .. with relative paths. Here we’ll go up a directory and then down to a different subdirectory.\n$ cd units\n$ cd ../assets\n$ pwd\n/home/jovyan/compute-skills-2024/assets\nAnd here we’ll go up two directories and then down to another subdirectory (but note that /home/jovyan/tmp may not exist for your server).\n$ cd ../../tmp  # Go up two directories and down.\n$ pwd\n/home/jovyan/tmp\n\n\nAbsolute versus relative paths\nAll of the above examples used relative paths to navigate based on your working directory at the moment you ran the command.\nWe can instead use absolute paths so that it doesn’t matter where we are when we run the command. Specifying an absolute path is done by having your path start with /, such as /home/jovyan. If the path doesn’t start with / then it is interpreted as being a relative path, relative to your working directory. Here we’ll go to the units subdirectory again, but this time using an absolute path.\n$ cd /home/jovyan/compute-skills-2024/units \n$ pwd\n/home/jovyan/compute-skills-2024/units\n\n\n\n\n\n\nAbsolute paths can be dangerous\n\n\n\nIt’s best to generally use relative paths, relative to the main directory of a project.\nUsing absolute paths is generally a bad idea for reproducibility and automation because the file system will be different on different machines, so your code wouldn’t work correctly anywhere other than your current machine.\n\n\n\n\nThe filesystem\nThe filesystem is basically a upside-down tree.\nFor example, if we just consider the compute-skills-2024 directory, we can see the tree structure using tree (not available on DataHub):\n$ cd /home/jovyan/compute-skills-2024\n$ tree\nOften (as is the case here), that would print out a lot of files and directories, so I’ll just print out the first few lines of the result here. One doesn’t usually use tree that much – our purpose here is to emphasize the hierarchical, nested structure of the filesystem.\n.\n├── assets\n│   ├── buttons-alt.ejs\n│   ├── buttons.ejs\n│   ├── schedule-alt.ejs\n│   ├── schedule.ejs\n│   ├── stat_bear.png\n│   ├── styles-alt.scss\n│   └── styles.css\n├── buttons.yml\n├── _freeze\n│   ├── site_libs\n│   │   ├── clipboard\n│   │   │   └── clipboard.min.js\n│   │   └── quarto-listing\n│   │       ├── list.min.js\n│   │       └── quarto-listing.js\nThe dot (.) means “this directory”, so the top of the tree here is the compute-skills-2024 directory itself, within which there are various subdirectories. Then within each of these are files and further subdirectories.\nIf we consider the entire filesystem, the top, or root of the tree, is the / directory. Within / there are subdirectories, such as /home (which contains users’ home directories where all of the files owned by a user are stored) and /bin (containing UNIX programs, aka ‘binaries’). We’ll use ls again, this time telling it the directory to operate on:\n$ ls /\nbin   dev  home  lib32  libx32  mnt  proc  run   srv  tmp  var\nboot  etc  lib   lib64  media   opt  root  sbin  sys  usr\nIf there is a user named jovyan, everything specific to that user would be stored in /home/jovyan. The shortcut ~jovyan refers to /home/jovyan. If you are the jovyan user, you can also refer to /home/jovyan by the shortcut ~.\n$ ls /home\njovyan shiny\n$ cd /home/jovyan\nGo to the home directory of the current user (which happens to be the jovyan user):\n$ cd ~\n$ pwd\n/home/jovyan\nGo to the home directory of the jovyan user explicitly:\n$ cd ~jovyan\n$ pwd\n/home/jovyan\nAnother useful directory is /tmp, which is a good place to put temporary files that you only need briefly and don’t need to save. These will disappear when a machine is rebooted.\n$ cd /tmp\n$ ls\njupyter-runtime\nWe can return to the most recent directory we were in like this:\n$ cd -\n$ pwd\n/home/jovyan",
    "crumbs": [
      "Modules",
      "Intro to Computing and Command Line (optional)"
    ]
  },
  {
    "objectID": "units/intro-computing.html#using-commands",
    "href": "units/intro-computing.html#using-commands",
    "title": "Introduction to Computing and the Command Line (optional)",
    "section": "Using commands",
    "text": "Using commands\n\nOverview\nLet’s look more at various ways to use commands. We just saw the ls command. Here’s one way we can modify the behavior of the command by passing a command option. Here the -F option (also called a flag) shows directories by appending / to anything that is a directory (rather than a file) and a * to anything that is an executable (i.e., a program).\n$ cd compute-skills-2024\n$ ls -F\n$ ls -F /usr/bin\nNext we’ll use multiple options to the ls command. -l shows extended information about files/directories. -t shows files/directories in order of the time at which they were last modified and -r shows in reverse order. Before I run ls, I’ll create an empty file using the touch command.\n$ cd\n$ touch example.txt\n$ ls -lrt\ntotal 14496\n-rw-r--r-- 1 jovyan jovyan    36365 Aug 29  2022 'Screen Shot 2021-10-26 at 10.54.07 AM.png'\n-rw-r--r-- 1 jovyan jovyan 14757718 Oct 25  2022  data_c80_regsample_3.dta\n-rw-r--r-- 1 jovyan jovyan     2436 Oct 25  2022  Untitled1.ipynb\n-rw-r--r-- 1 jovyan jovyan      470 Oct 25  2022  Untitled2.ipynb\n-rw------- 1 jovyan jovyan      438 Jan  3  2023  WHERE-ARE-MY-FILES.txt\ndrwxr-xr-x 5 jovyan jovyan     4096 May 30 16:12  python-workshop-2023\n-rw------- 1 jovyan jovyan       75 May 31 16:18  tmphn20xgkx\n-rw------- 1 jovyan jovyan       91 Jun  3 14:56  tmp4d_d65l_\ndrwxr-xr-x 3 jovyan jovyan     4096 Jun  4 15:58  test-private\ndrwxr-xr-x 4 jovyan jovyan     4096 Jul 19 14:55  test-jh\n-rw-r--r-- 1 jovyan jovyan      918 Jul 19 14:59  Untitled.ipynb\ndrwxr-xr-x 2 jovyan jovyan     4096 Jul 19 15:52  tmp\n-rw-r--r-- 1 jovyan jovyan        0 Jul 31 14:10  untitled.py\n-rw-r--r-- 1 jovyan jovyan      617 Jul 31 14:12  Untitled3.ipynb\ndrwxr-xr-x 7 jovyan jovyan     4096 Aug  1 15:45  compute-skills-2024\n-rw-r--r-- 1 jovyan jovyan        0 Aug  1 16:03  example.txt\nWhile each command has its own syntax, there are some rules usually followed. Generally, executing a command consists of four things:\n\nthe command\ncommand option(s)\nargument(s)\nline acceptance (i.e., hitting )\n\nHere’s an example:\n$ echo \"hello there\" &gt;&gt; example.txt\n$ echo \"and goodbye\" &gt;&gt; example.txt\n$ echo \"really now\" &gt;&gt; example.txt\n$ wc -l example.txt\n3 example.txt\nIn the above example, wc is the command, -l is a command option specifying to count the number of lines, example.txt is the argument, and the line acceptance is indicated by hitting the &lt;Return&gt; key at the end of the line.\nSo that invocation counts the number of lines in the file named example.txt.\nThe spaces are required and distinguish the different parts of the invocation. For this reason, it’s generally a bad idea to have spaces within file names. But if you do, you can use quotation marks to distinguish the file name, e.g.,\n$ ls -l \"name of my file with spaces.txt\"\nAlso, capitalization matters. For example -l and -L are different options.\nNote that options, arguments, or both might not be included in some cases. Recall that we’ve used ls without either options or arguments.\nArguments are usually one or more files or directories.\n\n\nOptions\nOften we can specify an option either in short form (as with -l here) or long form (--lines here), as seen in the following equivalent invocations:\n$ wc -l example.txt\n3 example.txt\n$ wc --lines example.txt\n3 example.txt\nWe can also ask for the number of characters with the -m option, which can be combined with the -l option equivalently in two ways:\n$ wc -lm example.txt\n  3 35 example.txt\n$ wc -l -m example.txt\n  3 35 example.txt\nOptions will often take values, e.g., if we want to get the first two lines of the file, the following invocations are equivalent:\n$ head -n 2 example.txt\n$ head --lines=2 example.txt\n$ head --lines 2 example.txt\n\n\nComments\nAnything that follows # is a comment and is ignored.\n$ # This is ignored\n$ ls  # Everything after the # is ignored\n compute-skills-2024                          test-jh           Untitled2.ipynb\n data_c80_regsample_3.dta                     test-private      Untitled3.ipynb\n\n\nGetting help with UNIX commands\nEssentially all UNIX commands have help information (called a man page), accessed using man.\n$ man ls\nOnce you are in the man page, you can navigate by hitting &lt;space&gt; (to scroll down) and the &lt;up&gt; and &lt;down&gt; arrows. You can search by typing /, typing the string you want to search for and hitting &lt;Return&gt;. You can use n and p for the next and previous search hits and q to quit out of the search.\nUnfortunately man pages are often quite long, hard to understand, and without examples. But the information you need is usually there if you take the time to look for it.\nAlso, UNIX commands as well as other programs run from the command line often provide help information via the --help option, e.g., for help on ls:\n$ ls --help\n\n\nTab completion\nIf you hit Tab the shell tries to figure out what command or filename you want based on the initial letters you typed.\nTry it with:\ncd com\nech\nThe first should allow you to get compute-skills-2024 and the second echo.\n\n\n\n\n\n\nTab completion everywhere\n\n\n\nLots of interactive programs have adopted the idea of tab completion, including Python/IPython and R.\n\n\n\n\nCommand history\nHit the up key. You should see the previous command you typed. Hit it again. You should see the 2nd most recent command.\nCtrl-a and Ctrl-e navigate to the beginning and end of a line. You can edit your previous command and then hit Enter to run the modified code.\n\n\nSeeing if a command or program is available\nYou can see if a command or program is installed (and where it is installed) using type.\n$ type grep\ngrep is /usr/bin/grep\n$ type R\nR is /usr/bin/R\n$ type python\npython is /srv/conda/bin/python",
    "crumbs": [
      "Modules",
      "Intro to Computing and Command Line (optional)"
    ]
  },
  {
    "objectID": "units/intro-computing.html#working-with-files",
    "href": "units/intro-computing.html#working-with-files",
    "title": "Introduction to Computing and the Command Line (optional)",
    "section": "Working with files",
    "text": "Working with files\n\nCopying and removing files\nYou’ll often want to make a copy (cp) of a file, move it (mv) between directories, or remove it (rm).\n$ cd ~/compute-skills-2024/units\n$ cp calc.py calc-new.py\n$ mv calc-new.py /tmp/.\n$ cd /tmp\n$ ls -lrt\ntotal 8\ndrwx-----T 2 jovyan jovyan 4096 Aug  1 16:15 jupyter-runtime\n-rw-r--r-- 1 jovyan jovyan  413 Aug  1 16:16 calc-new.py\nWhen we moved the file, the use of . in /tmp/. indicates we want to use the same name as the original file.\n$ rm calc-new.py\n$ ls -lrt\ntotal 4\ndrwx-----T 2 jovyan jovyan 4096 Aug  1 16:15 jupyter-runtime\n\n\n\n\n\n\nrm cannot be undone\n\n\n\nI used rm above to remove the file. Be very careful about removing files - there is no Trash folder in UNIX - once a file is removed, it’s gone for good.\n\n\nThe mv command is also used if you want to rename a file.\n$ cd ~/compute-skills-2020/units\n$ mv session3.qmd _sesson3.qmd\n$ ls",
    "crumbs": [
      "Modules",
      "Intro to Computing and Command Line (optional)"
    ]
  },
  {
    "objectID": "units/intro-computing.html#exercises-shell-commands",
    "href": "units/intro-computing.html#exercises-shell-commands",
    "title": "Introduction to Computing and the Command Line (optional)",
    "section": "Exercises: shell commands",
    "text": "Exercises: shell commands\n\n\n\n\n\n\nExercise 1\n\n\n\nWhere is gzip installed on the system? What are some other commands/executables that are installed in the same directory?\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nTry to run the following command mkdir ~/projects/drought. It will fail. Look in the help information on mkdir to figure out how to make it work without first creating the projects directory.\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\nFigure out how to list out the files in a directory in order of decreasing file size, as a way to see easily what the big files are that are taking up the most space. Modify this command to get the result in the ascending order.\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\nFigure out how to copy an entire directory and have the timestamps of the files retained rather than having the timestamps be the time that you copied the files.\nSee if you can combine the short form of an option with the long form of a different option.\nWhat happens if you use a single dash with the long form of an option. Are you able to interpret the error message? (Note that confusingly there are some situations one can use the long form with a single dash.)",
    "crumbs": [
      "Modules",
      "Intro to Computing and Command Line (optional)"
    ]
  },
  {
    "objectID": "units/intro-computing.html#running-processes",
    "href": "units/intro-computing.html#running-processes",
    "title": "Introduction to Computing and the Command Line (optional)",
    "section": "Running processes",
    "text": "Running processes\nWe’ll run a simple linear algebra operation in Python to illustrate how we can monitor what is happening on a machine.\n\n\n\n\n\n\nDataHub memory limits\n\n\n\nBe careful about increasing n in the example below when on DataHub. Basic DataHub virtual machines by default only have 1 GB memory, so don’t increase n below or you may run out of memory if running on DataHub and this can cause problems in your DataHub session. If you’re doing this as part of the workshop, we’ve increased those limits somewhat, so somewhat larger values of n should be fine.\n\n\n\n\nCode\nimport numpy as np\nimport time\n\ndef run_linalg(n):\n    z = np.random.normal(0, 1, size=(n, n))\n    print(time.time())\n    x = z.T.dot(z)   # x = z'z\n    print(time.time())\n    U = np.linalg.cholesky(x)  # factorize as x = U'U\n    print(time.time())\n\n## This allows us to run the code from the command line\n## without running it when we import the file as a module.\nif __name__ == '__main__':\n    run_linalg(4000)\n\n\npython calc.py\nWe might need to run it in a loop to be able to monitor the running process (since it finishes so quickly):\n\n\nCode\nfor ((i=0;i&lt;10;i++)); do\n  python calc.py\ndone\n\n\n\nMonitoring CPU and memory use\nWe can see CPU and memory usage via top.\nIf we see more than 100% CPU usage, that indicates that the process is running a computation in parallel using multiple threads.\nWhat about if we see less than 100% CPU usage?\n\nOur process might be busy doing I/O (reading/writing to/from disk).\nOur process might be waiting for data from the internet or from another machine on the network.\nThe machine might be running low on physical memory, which in some cases will involve using disk as additional memory (slow!).",
    "crumbs": [
      "Modules",
      "Intro to Computing and Command Line (optional)"
    ]
  },
  {
    "objectID": "units/additional-topics.html",
    "href": "units/additional-topics.html",
    "title": "Numerics, reproducibility, and automation",
    "section": "",
    "text": "Overview\n\n\n\nThis module presents some information on numerical analysis (random number generation and floating point precision), packaging, reproducibility, and automation.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/additional-topics.html#random-number-generation",
    "href": "units/additional-topics.html#random-number-generation",
    "title": "Numerics, reproducibility, and automation",
    "section": "Random number generation",
    "text": "Random number generation\nRandom numbers on a computer are actually (periodic) deterministic sequences that (hopefully) behave as if they were random.\n\nRandom number seed\nThe seed determines where in the cycle of the periodic sequence you are.\nIt’s critical for ensuring reproducibility when running code that uses random numbers\n\n\nCode\nimport numpy as np\nnp.random.seed(1)\nnp.random.normal(size = 5)\n\n\narray([ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763])\n\n\n\n\nCode\nnp.random.normal(size = 5)\n\n\narray([-2.3015387 ,  1.74481176, -0.7612069 ,  0.3190391 , -0.24937038])\n\n\n\n\nCode\nnp.random.seed(1)\nnp.random.normal(size = 10)\n\n\narray([ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763,\n       -2.3015387 ,  1.74481176, -0.7612069 ,  0.3190391 , -0.24937038])\n\n\n\n\nRandom number generators\nIf you don’t do anything, numpy will use a generator called the Mersenne Twister (that’s the default in R too).\nHowever the “default” RNG in numpy is a newer, better algorithm called PCG64.\n\n\nCode\n## Mersenne twister\nnp.random.seed(1)\nnp.random.normal(size = 5)\n\n\narray([ 1.62434536, -0.61175641, -0.52817175, -1.07296862,  0.86540763])\n\n\n\n\nCode\n## Mersenne twister, selected specifically\nrng = np.random.Generator(np.random.MT19937(seed = 1))\nrng.normal(size = 5)\n## Not clear why numbers differ from above. Seed setup might differ.\n\n\narray([ 2.04676909, -1.03653009,  0.72997546,  0.41584996, -0.1922969 ])\n\n\n\n\nCode\n## 'Default' PCG64\nrng = np.random.Generator(np.random.PCG64(seed = 1))\nrng.normal(size = 5)\n\n\narray([ 0.34558419,  0.82161814,  0.33043708, -1.30315723,  0.90535587])\n\n\n\n\nCode\nrng = np.random.default_rng(seed = 1)\nrng.normal(size = 5)\n\n\narray([ 0.34558419,  0.82161814,  0.33043708, -1.30315723,  0.90535587])\n\n\nSome cautions (detailed by Philip Stark and Kellie Ottoboni):\n\nseeds with many zeros can be problematic.\nMersenne Twister not as good as PCG64.\nBe particularly cautious to use a good RNG when doing permutation and taking random samples.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/additional-topics.html#floating-point-precision",
    "href": "units/additional-topics.html#floating-point-precision",
    "title": "Numerics, reproducibility, and automation",
    "section": "Floating point precision",
    "text": "Floating point precision\n\n\nCode\n0.3 - 0.2 == 0.1\n0.3\n0.2\n0.1 # Hmmm...\n\n\n0.1\n\n\n\nDouble-precision accuracy\nNumbers in most languages are stored by default as double precision floating point numbers.\n\n8 bytes = 64 bits = double precision\n4 bytes = 32 bits = single precision\n\n(GPU libraries often use 4 bytes or even fewer.)\n\n\nCode\ndef dg(x, form = '.20f'):\n    print(format(x, form))\n\na = 0.3\nb = 0.2\ndg(a)\ndg(b)\ndg(a-b)\ndg(0.1)\n\n\n0.29999999999999998890\n0.20000000000000001110\n0.09999999999999997780\n0.10000000000000000555\n\n\nHow many digits of accuracy do we have?\nSame thing regardless of the size of the number:\n\n\nCode\n12345678.1234567812345678\n\n\n12345678.123456782\n\n\n\n\nCode\n12345678123456781234.5678\n\n\n1.234567812345678e+19\n\n\n\n\nCode\ndg(12345678123456781234.5678)\n\n\n12345678123456780288.00000000000000000000\n\n\nThis occurs because of how the 64 bits in a double precision floating point number are allocated to give a large range of numbers in terms of magnitude and high precision in terms of digits of accuracy.\n\n\nComparisons\nLet’s see what kinds of numbers we can safely compare for exact equality with ==.\n\n\nCode\nx = .5 - .2\nx == 0.3\nx = 1.5 - .2\nx == 0.3\n\nx = .5 - .5\nx == 0\nx = .5 - .2  -.3\nx == 0\nx = (.5 - .2) - (.51 - .21)\nx == 0\n\nnp.isclose(x, 0)\n\n\n\n\nCalculation errors\nLet’s consider accuracy of subtraction.\n\n\nCode\n1.1234 - 1.0\n\n\n0.12339999999999995\n\n\n\n\nCode\n123456781234.1234 - 123456781234.0\n\n\n0.1233978271484375\n\n\nThis is called catastrophic cancellation.\nDo you think calling it “catastrophic” is too extreme? If so, consider this.\n\n\nCode\n81.0 - 80.0\n\n\n1.0\n\n\n\n\nCode\n12345678123456781.0 -12345678123456780.0\n\n\n0.0\n\n\nWhat’s the derivative of \\(sin(x)\\)? Let’s see what kind of accuracy we can get.\n\n\nCode\ndef deriv(f, x, eps=1e-8):\n   return (f(x+eps) - f(x)) / eps\n\nnp.cos(0.2)\n\nderiv(np.sin, 0.2)\n\nderiv(np.sin, 0.2, 1e-12)\nderiv(np.sin, 0.2, 1e-14)\nderiv(np.sin, 0.2, 1e-15)\nderiv(np.sin, 0.2, 1e-16)\nderiv(np.sin, 0.2, 1e-17)\n\n\n\n\nLinear algebra errors\nThe errors seen in doing calculations, such as catastrophic cancellation, cascaded through derivative estimation. That also happens when doing linear algebra operations.\nHere’s an example where mathematically all the eigenvalues are real-valued and positive, but not on the computer.\n\n\nCode\nimport scipy as sp\n\nxs = np.arange(100)\ndists = np.abs(xs[:, np.newaxis] - xs)\n# This is a p.d. matrix (mathematically).\ncorr_matrix = np.exp(-(dists/10)**2)\n# But not numerically...\nsp.linalg.eigvals(corr_matrix)[80:99]\n\n\narray([ 1.43024256e-16+1.28433951e-16j,  1.43024256e-16-1.28433951e-16j,\n        1.49210347e-16+4.87070558e-17j,  1.49210347e-16-4.87070558e-17j,\n       -1.54661687e-16+1.25601177e-16j, -1.54661687e-16-1.25601177e-16j,\n       -2.07808543e-16+3.73312254e-17j, -2.07808543e-16-3.73312254e-17j,\n        9.83783628e-17+7.20174529e-17j,  9.83783628e-17-7.20174529e-17j,\n        2.37821218e-18+1.00101181e-16j,  2.37821218e-18-1.00101181e-16j,\n        5.29254936e-17+0.00000000e+00j, -1.62444574e-16+0.00000000e+00j,\n       -2.74621910e-17+7.55223038e-17j, -2.74621910e-17-7.55223038e-17j,\n       -9.08016006e-17+3.79199791e-17j, -9.08016006e-17-3.79199791e-17j,\n       -3.25243092e-17+0.00000000e+00j])\n\n\n\n\nOverflow and underflow\nHaving a finite number of bits to represent each number means there are minimum and maximum numbers that can be expressed.\n\n\nCode\n1.38e5000\n1.38e-400\n\n\n0.0\n\n\n\n\n\n\n\n\nHow much do we need to worry about overflow and underflow?\n\n\n\nQ: Roughly how many observations would it take before we underflow in calculating a likelihood?\n\n10\n100\n1000\n100000\n100000000\n\n\n\n\n\nCode\nimport numpy as np\nimport scipy as sp\n\nn = 10\n\nx = np.random.normal(size=n)\nnp.prod(sp.stats.norm.pdf(x))\n\nloglik = np.sum(sp.stats.norm.logpdf(x))\nloglik\nnp.exp(loglik)\n\n\n2.0739518337814167e-08\n\n\n\n\n\n\n\n\nWork with probabilities and densities on the log scale. Almost always.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/additional-topics.html#exercise-numerical-issues-with-newtons-method",
    "href": "units/additional-topics.html#exercise-numerical-issues-with-newtons-method",
    "title": "Numerics, reproducibility, and automation",
    "section": "Exercise: numerical issues with Newton’s method",
    "text": "Exercise: numerical issues with Newton’s method\nLook at your partner’s code in terms of how it handles the stopping criterion or (for the 1-d case) the finite difference estimate of the gradient and Hessian.\nMake a pull request that tries to improve how that is handled.\nThen review the pull request your partner makes in your repository. Iterate with your partner until you are happy to merge the pull request into your repository. Remember to then run git pull to get the changes in the local copy of the repository.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/additional-topics.html#packages",
    "href": "units/additional-topics.html#packages",
    "title": "Numerics, reproducibility, and automation",
    "section": "Packages",
    "text": "Packages\nWhat’s a package? In general it is software that is provided as a bundle that can be downloaded and made available on your computer. Some packages (e.g., R, Python themselves) are stand-alone packages. Others (such as R packages and Python packages) are add-on functionality that works with and extends the functionality of the stand-alone software.\nWhat do we need to have a Python package?\n\nA basic Python package\nA Python package is a directory containing one or more modules and with a file named __init__.py that is called when a package is imported and serves to initialize the package.\nLet’s create a basic package.\nmkdir mypkg\n\ncat &lt;&lt; EOF &gt; mypkg/__init__.py\n## Make objects from mymod.py available as mypkg.foo\nfrom mypkg.mymod import *\n\nprint(\"Welcome to my package.\")\nEOF\n\ncat &lt;&lt; EOF &gt; mypkg/mymod.py\nx = 7\n\ndef myfun(val):\n    print(\"The arg is: \", str(val), \".\", sep = '')\nEOF\nNote that if there were other modules, we could have imported from those as well.\nNow we can use the objects from the module without having to know that it was in a particular module (because of how __init__.py was set up).\n\n\nCode\nimport mypkg\nmypkg.x\nmypkg.myfun(7)\n\n\nNote that one can set __all__ in an __init__.py to define what is imported, which makes clear what is publicly available and hides what is considered internal.\n\n\nA minimal “real” package\nFernando has a this toy example package.\nLet’s clone the repository and see if we can install it.\ngit clone https://github.com/fperez/mytoy\ncd mytoy\npip install --user .\ncd\nls .local/lib/python3.11/site-packages\n\n\nCode\nimport mytoy\n\nmytoy.toy(7)\n\n\nIt would take more work to make the package available in a repository such as PyPI or via Conda.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/additional-topics.html#exercise-make-your-own-package",
    "href": "units/additional-topics.html#exercise-make-your-own-package",
    "title": "Numerics, reproducibility, and automation",
    "section": "Exercise: Make your own package",
    "text": "Exercise: Make your own package\nMake a package out of your Newton method code, following the structure of mytoy. Include your tests as part of the package.\nSee if you can install your package, run the tests, and use the package, following the README.md of mytoy.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/additional-topics.html#installing-packages",
    "href": "units/additional-topics.html#installing-packages",
    "title": "Numerics, reproducibility, and automation",
    "section": "Installing packages",
    "text": "Installing packages\nIf a package is on PyPI or available through Conda but not on your system, you can install it easily (usually). You don’t need root permission on a machine to install a package, though you may need to use pip install --user or set up a new Conda environment.\nPackages often depend on other packages. In general, if one package depends on another, pip or conda will generally install the dependency automatically.\nOne advantage of Conda is that it can also install non-Python packages on which a Python package depends, whereas with pip you sometimes need to install a system package to satisfy a dependency.\n\n\n\n\n\n\nFaster installation with Mamba\n\n\n\nIt’s not uncommon to run into a case where conda has trouble installing a package because of version inconsistencies amongst the dependencies. mamba is a drop-in replacement for conda and often does a better job of this “dependency resolution”. We use mamba by default on the SCF.\nWith newer versions of Conda, you can use the libmamba dependency “resolver” by running conda config --set solver libmamba, which adds solver: libmamba to your .condarc file.\n\n\n\nReproducibility and package management\nFor reproducibility, it’s important to know the versions of the packages you use (and the version of Python). pip and conda make it easy to do this. You can create a requirements file that captures the packages you are currently using (and, critically, their versions) and then install exactly that set of packages (and versions) based on that requirements file.\n## Reproducing using pip.\npip freeze &gt; requirements.txt\npip install -r requirements.txt\n\n## Reproducing a Conda environment.\nconda env export &gt; environment.yml\nconda env create -f environment.yml\nConda is a general package manager. You can use it to manage Python packages but lots of other software as well, including R and Julia.\n\nFully isolating your Conda environment\nConda environments provide an additional layer of modularity/reproducibility, allowing you to set up a fully reproducible environment for your computation. Here (by explicitly giving python=3.11) the Python 3.11 executable and all packages you install in the environment are fully independent of whatever Python executables are installed on the system. (That said, there are some caveats that can make it a bit of headache to ensure full isolation.)\ntype python\nconda create -n my_iso_env python=3.11\nsource activate my_iso_env\ntype python\nconda install numpy\n\n\n\n\n\n\nActivating an environment\n\n\n\nIf you use conda activate rather than source activate, Conda will prompt you to run conda init, which will make changes to your ~/.bashrc that, for one, activate the Conda base environment automatically when a shell is started. This may be fine, but it’s helpful to be aware.\n\n\n\n\n\nPackage locations\nPackages in Python (and in R, Julia, etc.) may be installed in various places on the filesystem, and it sometimes it is helpful (e.g., if you end up with multiple versions of a package installed on your system) to be able to figure out where on the filesystem the package is being loaded from.\n\npkgname.__file__ will show where the imported package is installed.\npkname.__version__ will show the version of the package (as will pip list or conda list, for all packages).\nsys.path shows where Python looks for packages on your system.\n\npackages installed via pip will generally be in ~/.local/lib/python3.X/site-packages.\n\n\n\n\nSource vs. binary packages\nThe difference between a source package and a binary package is that\n\na source package has the raw Python (and C/C++ and Fortran, in some cases) code as text files\na binary package has all the non-Python code in a binary/non-text format, with the C/C++ and Fortran code already having been compiled.\n\nIf you install a package from source, C/C++/Fortran code will be compiled on your system (if the package has such code). That should mean the compiled code will work on your system, but requires you to have a compiler available and things properly configured. A binary package doesn’t need to be compiled on your system, but in some cases (e.g., if you got the wrong binary version) the code may not run on your system because it was compiled in such a way that is not compatible with your system.\nPython wheels are a binary package format for Python packages. Wheels for some packages will vary by platform (i.e., operating system) so that the package will install correctly on the system where it is being installed.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/additional-topics.html#docker-containers",
    "href": "units/additional-topics.html#docker-containers",
    "title": "Numerics, reproducibility, and automation",
    "section": "Docker containers",
    "text": "Docker containers\nDocker containers share some similarities with Conda environments except that you provide a full specification for the Linux operating system you want to use and software you want installed.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/additional-topics.html#example-1-binder",
    "href": "units/additional-topics.html#example-1-binder",
    "title": "Numerics, reproducibility, and automation",
    "section": "Example 1: Binder",
    "text": "Example 1: Binder\nOne example is using Binder to open a Jupyter notebook in an executable environment.\nBased on a configuration (various options are possible for how to specify the configuration), Binder will create a Docker container with the needed software installed.\nThe most common configuration format is to provide a Conda environment file. Binder will then create a Conda environment inside the Docker (Linux) container. The Conda environment will contain the packages specified in the environment file.\nLet’s set up a Binder environment “Geospatial analytics in Python with Geopandas” that can access the notebooks and materials provided in the repository in a computational environment designed to use the notebooks reliably and reproducibly.\nIn some cases an image for the container will already be available, and all that needs to happen is to start a virtual machine using that image as the computational environment. In other cases (e.g., with a configuration you’ve just created), the Docker container and Conda environment need to be set up.\nIf we’re familiar with what happens when Docker containers and Conda environments are set up, we can see in the Binder logs that a Docker container is set up (using Ubuntu Linux) and one of the steps of doing that is to create a Conda environment within the container.\nLet’s see the steps that are run if we use the mytoy repository to start a Binder environment at ovh.mybinder.org, specifying fperez/mytoy as the repository. (Note that in a number of cases, the startup has failed, probably because mybinder has very limited resources for providing cloud compute resources. We are using ovh.mybinder.org rather than mybinder.org in hopes that is more likely to succeed.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/additional-topics.html#example-2-github-actions-for-automated-testing",
    "href": "units/additional-topics.html#example-2-github-actions-for-automated-testing",
    "title": "Numerics, reproducibility, and automation",
    "section": "Example 2: GitHub Actions for automated testing",
    "text": "Example 2: GitHub Actions for automated testing\nA second example is using GitHub Actions (GHA) to automate activities such as testing. To set up a GitHub Actions workflow, one\n\nspecifies when the workflow will run (e.g., when a push or pull request is made, or only manually)\nprovides instructions for how to set up the environment for the workflow\nprovides the operations that the workflow should run.\n\nA good example is running tests whenever you make a commit to a repository containing software.\nWith GHA, you specify the operating system and then run the steps you specify in .github/workflows/some_action.yml. Some steps will customize the environment as the initial steps and then additional step(s) will run shell or other code to run your workflow. You use pre-specified operations (called actions) to do common things (such as checking out a GitHub repository and installing commonly used software).\nWhen triggered, GitHub will run the steps in a virtual machine, which is called the runner.\n\nJoint demo/exercise\nWe’ll walk through the steps of setting up automated testing for the mytoy example package. Why do this? It’s common to have testing pass locally on your own machine, but fail for various reasons when done elsewhere.\nThe workflow is specified using a YAML file placed in the .github/workflows directory of the repository.\nHere’s an example YAML file for testing the mytoy package:\non:\n  push:\n    branches:\n    - main\n\njobs:\n  CI:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n\n    # Install dependencies\n    - name: Set up Python \n      uses: actions/setup-python@v5\n      with:\n        python-version: 3.12\n\n    - name: Install mytoy\n      run: |\n        cd mytoy\n        pip install --user .\n\n    - name: Run tests\n      run: |\n        cd mytoy\n        pytest\nWe’ll first run this with the current tests for mytoy, which should pass when run via GitHub Actions. We can take a look at the output.\nNext, let’s introduce a failing test to see what the output looks like and get a sense for how to debug it.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/additional-topics.html#example-3-github-actions-for-publishing-webpages",
    "href": "units/additional-topics.html#example-3-github-actions-for-publishing-webpages",
    "title": "Numerics, reproducibility, and automation",
    "section": "Example 3: GitHub Actions for publishing webpages",
    "text": "Example 3: GitHub Actions for publishing webpages\nWe can use GitHub Actions with GitHub pages to easily publish websites, where we make changes to the repository and the workflow causes the website to be updated.\nHere’s the GitHub Actions workflow (a YAML file) that publishes the website for the spring 2023 version of Statistics 159/259. Any commits made in the main branch cause the website to be updated.\n\nConfiguring GitHub Pages\nTo set up GitHub Pages for a repository, go to https://github.com/github_org/repository/settings/pages and select Source -&gt; Deploy from a branch and then choose gh-pages as the branch (first creating the gh-pages branch if necessary). The website should appear at github_org.github.io/repository.\n\n\nQuarto-based websites\nIn fact the website for this workshop was done using Quarto, which uses GitHub Pages and GitHub Actions behind the scenes.\nChris runs quarto publish gh-pages to update the site. Quarto will (on the local machine) render the html (convert the Markdown to html) and then behind the scenes Quarto uses GitHub Actions and GitHub Pages (via the `gh-pages branch) to publish the website.",
    "crumbs": [
      "Modules",
      "Numerics and Reproducibility"
    ]
  },
  {
    "objectID": "units/solutions-python.html",
    "href": "units/solutions-python.html",
    "title": "SOLUTIONS: Introduction to Python (optional)",
    "section": "",
    "text": "Exercise 1\n\n\n\nUsing the section on “Built-in Types” from the official “The Python Standard Library” reference, figure out how to compute: - \\(\\sqrt(-1)\\)\n- \\(\\exp(1.5)\\) - \\((\\lceil \\frac{3}{4} \\rceil \\times 4)^3\\),\n\n\n\n\n\n\n\n\nExercise 1 Solution\n\n\n\n\n\n\n\nCode\npow(-1, 0.5)\n(-1)**0.5\n\nimport math\nmath.exp(1.5)\n\n(math.ceil(3/4) * 4)**3\n\n\n64\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nIs 1.0 of the integer type? What about 1? Is the result of 5/3 - 2/3 of the integer type? Is the mathematical value seen in Python an integer?\nHere’s a numerical puzzle. Why does the last computation not work, when the others do? And, for those of you coming from R, which of these computations don’t work in R?\n\n\nCode\n100000**10\n100000.0**10\n100000**100\n100000.0**100\n\n\n\n\n\n\n\n\n\n\n\nExercise 2 Solution\n\n\n\n\n\n\n\nCode\ntype(1.0)\ntype(1)\ntype(5/3-2/3)\n5/3-2/3 == 1\n\ntype(100000**10)\ntype(100000.0**10)\n\n\nfloat"
  },
  {
    "objectID": "units/solutions-python.html#python-fundamentals",
    "href": "units/solutions-python.html#python-fundamentals",
    "title": "SOLUTIONS: Introduction to Python (optional)",
    "section": "",
    "text": "Exercise 1\n\n\n\nUsing the section on “Built-in Types” from the official “The Python Standard Library” reference, figure out how to compute: - \\(\\sqrt(-1)\\)\n- \\(\\exp(1.5)\\) - \\((\\lceil \\frac{3}{4} \\rceil \\times 4)^3\\),\n\n\n\n\n\n\n\n\nExercise 1 Solution\n\n\n\n\n\n\n\nCode\npow(-1, 0.5)\n(-1)**0.5\n\nimport math\nmath.exp(1.5)\n\n(math.ceil(3/4) * 4)**3\n\n\n64\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nIs 1.0 of the integer type? What about 1? Is the result of 5/3 - 2/3 of the integer type? Is the mathematical value seen in Python an integer?\nHere’s a numerical puzzle. Why does the last computation not work, when the others do? And, for those of you coming from R, which of these computations don’t work in R?\n\n\nCode\n100000**10\n100000.0**10\n100000**100\n100000.0**100\n\n\n\n\n\n\n\n\n\n\n\nExercise 2 Solution\n\n\n\n\n\n\n\nCode\ntype(1.0)\ntype(1)\ntype(5/3-2/3)\n5/3-2/3 == 1\n\ntype(100000**10)\ntype(100000.0**10)\n\n\nfloat"
  },
  {
    "objectID": "units/solutions-python.html#analyzing-patient-data",
    "href": "units/solutions-python.html#analyzing-patient-data",
    "title": "SOLUTIONS: Introduction to Python (optional)",
    "section": "2. Analyzing Patient Data",
    "text": "2. Analyzing Patient Data\n\n\n\n\n\n\nExercise 2\n\n\n\nNote that ? and ?? only work in IPython (or a Jupyter notebook). For help in plain Python, use help(np.ndim).\n\nWhat happens if you type np.ndim?? (i.e., use two question marks)? What additional do you see?\nWhat does np.ndim() do? How does it execute under the hood? Consider why the following uses of ndim both work.\n\n\nCode\na = np.array([0, 1, 2])\na.ndim\nnp.ndim(a)\n\n\nNow explain why only one of these works.\n\n\nCode\na = [0, 1, 2]\na.ndim\nnp.ndim(a)\n\n\nType np.array? in a Notebook or at the IPython prompt. Briefly skim the docstring. nparray allows you to construct numpy arrays.\nType np. followed by the &lt;Tab&gt; key in a Notebook or at the IPython prompt. Choose two or three of the completions and use ? to view their docstrings. In particular, pay attention to the examples provided near the end of the docstring and see whether you can figure out how you might use this functionality.\n\n\n\n\n\n\n\n\n\nExercise 1 Solution\n\n\n\n\n\n\n\nCode\na = [0, 1, 2]\n# a.ndim  # This errors out.\n\nimport numpy as np\nnp.asarray(a)\nnp.asarray(a).ndim\n\n\n1"
  },
  {
    "objectID": "units/solutions-python.html#visualizing-tabular-data",
    "href": "units/solutions-python.html#visualizing-tabular-data",
    "title": "SOLUTIONS: Introduction to Python (optional)",
    "section": "3. Visualizing Tabular Data",
    "text": "3. Visualizing Tabular Data\n\n\n\n\n\n\nExercise\n\n\n\nUsing the following code, read in the GapMinder data using Pandas (to be discussed later) and run the following code to make the variables easily available (you don’t need to know anything about Pandas).\n\n\nCode\nimport numpy as np\nimport pandas as pd\ndat = pd.read_csv('gapminder.csv')\nlifeExp = np.array(dat.lifeExp)\ngdpPercap = np.array(dat.gdpPercap)\nyear = np.array(dat.year)\n\n## Hint: slicing using an array of booleans\n## gdpPercap[year &gt; 2010]\n\n\n\nMake a scatterplot of lifeExp vs gdpPerCap for 2007; make sure you have nice axis labels and title.\nConsider whether plotting income on a logarithmic axis is a better way to display the data.\nUsing at least two years, make an array of plots (in one figure) where each subplot is a different year.\n\n\n\n\n\n\n\n\n\nExercise solution\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\ndat = pd.read_csv('gapminder.csv')\nlifeExp = np.array(dat.lifeExp)\ngdpPercap = np.array(dat.gdpPercap)\nyear = np.array(dat.year)\n\nimport matplotlib.pyplot as plt\nmyplot = plt.plot(gdpPercap, lifeExp, 'bo')\nplt.show()\n\nmyplot = plt.plot(np.log(gdpPercap), lifeExp, 'bo')\nplt.show()\n\nfig = plt.figure()\nsubplot1 = fig.add_subplot(1, 2, 1)\nsubplot2 = fig.add_subplot(1, 2, 2)\n\nsubplot1.plot(np.log(gdpPercap[year == 1952]), lifeExp[year == 1952], 'bo')\nsubplot2.plot(np.log(gdpPercap[year == 2007]), lifeExp[year == 2007], 'bo')\n\nsubplot1.set_title('1952')\nsubplot2.set_title('2007')\n\nsubplot1.set_xlabel('per capita GDP (log dollars)')\nsubplot1.set_ylabel('life expectancy (years)')\n\nsubplot2.set_xlabel('per capita GDP (log dollars)')\n\nplt.show()"
  },
  {
    "objectID": "units/solutions-python.html#storing-multiple-values-in-lists",
    "href": "units/solutions-python.html#storing-multiple-values-in-lists",
    "title": "SOLUTIONS: Introduction to Python (optional)",
    "section": "4. Storing Multiple Values in Lists",
    "text": "4. Storing Multiple Values in Lists\n\n\n\n\n\n\nExercise 1\n\n\n\nCreate a list of numbers, called x1. Reverse the order of the items in the list using slicing. Now reverse the order of the items using a list method. How does using the method differ from slicing? Hint: you can type x. followed by the &lt;Tab&gt; key in a Notebook or at the IPython prompt to find the various methods that can be applied to a list.\n\n\n\n\n\n\n\n\nExercise 1 solution\n\n\n\n\n\n\n\nCode\nx1 = [1, 2, 3, 4]\nprint(x1[::-1])\nprint(x1)\nx1.reverse()\nprint(x1)\n\n\n[4, 3, 2, 1]\n[1, 2, 3, 4]\n[4, 3, 2, 1]\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nFigure out some different ways of combining your list of numbers with a list of strings to create a single list of mixed type elements. (Hint: you can type x. followed by the &lt;Tab&gt; key in a Notebook or at the IPython prompt to find the various methods that can be applied to a list.)\nNow try to sort the resulting list. What happens?\n\n\n\n\n\n\n\n\n\nExercise 2 solution\n\n\n\n\n\n\n\nCode\nx1 = [1, 2, 3, 4]\nx2 = ['apple', 'banana']\n\nprint(x1 + x2)\nx1.append(x2)\nprint(x1)\n\nx1 = [1, 2, 3, 4]\nx1.extend(x2)\nprint(x1)\n\n# x1.sort() # This errors out.\n\n\n[1, 2, 3, 4, 'apple', 'banana']\n[1, 2, 3, 4, ['apple', 'banana']]\n[1, 2, 3, 4, 'apple', 'banana']\n\n\n\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\nWhat does the following tell you about copying and use of memory in lists in Python?\n\n\nCode\na = [1, 3, 5]\nb = a\nid(a)\nid(b)\n# this should confirm what you might suspect\na[1] = 5\n\n\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\n\n\nWhat does the following tell you about copying and use of memory in lists in Python?\n\n\nCode\na = [1, 3, 5]\nb = a\nid(a)\nid(b)\n\nprint(id(a) == id(b))\na[1] = 5\na\nb\n\n\nTrue\n\n\n[1, 5, 5]"
  },
  {
    "objectID": "units/solutions-python.html#repeating-actions-with-loops",
    "href": "units/solutions-python.html#repeating-actions-with-loops",
    "title": "SOLUTIONS: Introduction to Python (optional)",
    "section": "5. Repeating Actions with Loops",
    "text": "5. Repeating Actions with Loops\n\n\n\n\n\n\nExercises\n\n\n\n\nSee what [1, 2, 3] + 3 returns. Try to explain what happened and why.\nHow would you do the same task using a for loop? The range function may be helpful as might the enumerate function.\nUse list comprehension to perform the same element-wise addition of the scalar to the list of scalars.\nChange [1, 2, 3] to be a numpy array and then add three using + 3.\n\n\n\n\n\n\n\n\n\nExercises solutions\n\n\n\n\n\n\n\nCode\nmylist = [1, 2, 3]\n\n## for loop\nfor i in range(len(mylist)):\n    mylist[i] += 3\n\n## list comprehension\n[x+3 for x in mylist]\n\n## numpy (best!)\nnplist = np.array([mylist]) + 3"
  },
  {
    "objectID": "units/solutions-python.html#creating-functions",
    "href": "units/solutions-python.html#creating-functions",
    "title": "SOLUTIONS: Introduction to Python (optional)",
    "section": "8. Creating Functions",
    "text": "8. Creating Functions\n\n\n\n\n\n\nExercise 1\n\n\n\nDefine a function called sqrt that will take the square root of a number and will (if requested by the user) set the square root of a negative number to 0.\n\n\n\n\n\n\n\n\nExercise 1 solution\n\n\n\n\n\n\n\nCode\ndef sqrt(x, complex=False):\n    if complex and x &lt; 0:\n       return 0\n    return pow(x, 0.5)\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nWhat happens if you modify a list within a function in Python; why do you think this is?\nWhat happens if you modify a single number (scalar) within a function in Python; why do you think this is?\n\n\n\n\n\n\n\n\n\nExercise 2 solution\n\n\n\n\n\n\n\nCode\nmylist = [1, 2, 3]\nmynum = 1\n\ndef testfun(x):\n    x[1] = 9\n\ndef testfun2(x):\n    x = 9\n\ntestfun(mylist)\nprint(mylist)\n\ntestfun2(mynum)\nprint(mynum)\n\n\n[1, 9, 3]\n1"
  },
  {
    "objectID": "units/solutions-python.html#extra-part-1.-some-other-useful-data-structures",
    "href": "units/solutions-python.html#extra-part-1.-some-other-useful-data-structures",
    "title": "SOLUTIONS: Introduction to Python (optional)",
    "section": "EXTRA Part 1. Some other useful data structures",
    "text": "EXTRA Part 1. Some other useful data structures\n\n\n\n\n\n\nExercise 1\n\n\n\n\nWhat’s weird about this? What are the types involved?\n\n\nCode\nz = x,y\na,b = x,y\n\n\nCreate the following: x=5 and y=99. Now swap their values using a single line of code. (For R users, how would you do this in R?)\n\n\n\n\n\n\n\n\n\nExercise 1 solution\n\n\n\n\n\n\n\nCode\nx = 5\ny = 99\n\nz = x,y\na,b = x,y\n\nprint(type(z))\nprint(type(a))\n\ny,x = x,y\n\n\n&lt;class 'tuple'&gt;\n&lt;class 'int'&gt;\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nWhat happens when you multiply a tuple by a number?\n\n\n\n\n\n\n\n\nExercise 2 solution\n\n\n\n\n\n\n\nCode\nx = (1,2,3)\nx * 3\n\n\n(1, 2, 3, 1, 2, 3, 1, 2, 3)\n\n\n\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\nWhy do you think there is no reverse method for tuples?\nWhat’s nice about using immutable objects in your code?\n\n\n\n\n\n\n\n\n\nExercise 3 solution\n\n\n\n\n\nFor a list, reverse reverses the elements in place in the list, but this would violate the rule that tuples cannot be modified.\nSometimes we want to use fixed values that can’t change, and using immutable objects is a way to guarantee that. It’s an aspect of “defensive” programming.\n\n\n\n\n\n\n\n\n\nExercise 4\n\n\n\nHow can you add an item to a dictionary?\n\n\n\n\n\n\n\n\nExercise 4 solution\n\n\n\n\n\n\n\nCode\nx = {\"department\": \"Statistics\", \"location\": \"Evans\", \"floor\": 3}\nx.update({'university': 'Berkeley'})\nx['country'] = 'USA'\nprint(x)\n\n\n{'department': 'Statistics', 'location': 'Evans', 'floor': 3, 'university': 'Berkeley', 'country': 'USA'}\n\n\n\n\n\n\n\n\n\n\n\nExercise 5\n\n\n\nHow do you combine two dictionaries into a single dictionary?\n\n\n\n\n\n\n\n\nExercise 5 solution\n\n\n\n\n\n\n\nCode\nx = {\"department\": \"Statistics\", \"location\": \"Evans\", \"floor\": 3}\ny = {'university': 'Berkeley'}\n\nz = x.copy()\nz.update(y)\nprint(z)\n\n\n{'department': 'Statistics', 'location': 'Evans', 'floor': 3, 'university': 'Berkeley'}\n\n\n\n\n\n\n\n\n\n\n\nExercise 6 (for R users)\n\n\n\n\nWhat are some analogs to dictionaries in R?\nHow are dictionaries different from such analogous structures in R?\n\n\n\n\n\n\n\n\n\nExercise 6 solution\n\n\n\n\n\nNamed arrays and named lists can function like dictionaries, but the names can be repeated, unlike with dictionaries."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Berkeley Statistics Computational Skills Workshop",
    "section": "",
    "text": "Ed Discussion\n\n  DataHub\n\n  GitHub\n\n  PollEv\n\n\nNo matching items\nSkills related to computation, coding, and reproducibility are crucial for modern statistical work (applied and methodological), as well as for serving as graduate student instructor for Statistics and Data Science courses. Incoming Statistics graduate students arrive with a wide variety of backgrounds in these areas.\nThe department will be holding a (new this year) computational skills workshop the week before classes start, focusing on best practices for computation, code development and statistics/data science workflows.\nAll incoming PhD and MA students are expected to attend the workshop, which will be held August 22-23. Those who already have extensive work or other experience with the topics can request to opt out of the workshop via this form (which will be considered by department faculty), as can PhD students who plan to focus exclusively on theory and feel the computing skills/tools covered in the workshop aren’t relevant for them.\nIn advance, there will also be an optional introduction to computing concepts and to Python for those students (particularly those taking Statistics 243) to be held August 20-21. If you are interested, please sign up for the optional introduction.\nSee the syllabus/overview for more details on workshop content.",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "index.html#logistics-times-and-locations",
    "href": "index.html#logistics-times-and-locations",
    "title": "Berkeley Statistics Computational Skills Workshop",
    "section": "Logistics (times and locations)",
    "text": "Logistics (times and locations)\n\nOptional Sessions (Tuesday/Wednesday)\nLocation: 334 Evans Hall\nLunch: On your own.\nSnacks: Light refreshments during morning and afternoon breaks\nTimes:\n\nTuesday August 20, 8:30 a.m - 4:30 p.m. with a one-hour lunch break.\nWednesday August 21, 8:30 a.m - 3:00 p.m. with a one-hour lunch break.\n\n\n\nCore Sessions (Thursday/Friday)\nLocation: 101 Barker Hall\n\nThursday August 22, 8:30 a.m - 4:30 p.m. with a one-hour lunch break.\nFriday August 23, 8:30 a.m - 3:00 p.m. with a one-hour lunch break.\n\nLunch: On your own.\nSnacks: Light refreshments during morning and afternoon breaks",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "index.html#preparation-for-the-workshop",
    "href": "index.html#preparation-for-the-workshop",
    "title": "Berkeley Statistics Computational Skills Workshop",
    "section": "Preparation for the Workshop",
    "text": "Preparation for the Workshop\n\nIf you don’t already have a GitHub account, please sign up for an account.\nBring your laptop as the workshop will focus on hands-on work.\nWe’ll be using the campus DataHub as our primary computational environment, so you don’t need to install anything on your laptop, though you can install Git and Python if you wish.",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Berkeley Statistics Computational Skills Workshop",
    "section": "Schedule",
    "text": "Schedule\n\n\n   Session 0 (optional)\n\n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Aug 20:\n           \n           Module 1 Introduction to Computing\n           \n                \n           \n                \n           \n        \n\n           \n           \n           Module 2 Introduction to Python\n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Aug 21:\n           \n           Lab 1 Mini project\n           \n                \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Session 1\n\n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Aug 22:\n           \n           Module 3 Computational Best Practices\n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Aug 23:\n           \n           Module 4 Additional Topics\n           \n                \n           \n                \n           \n        \n   \n   \n   \n  \n\n\nNo matching items",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Overview",
    "section": "",
    "text": "The workshop will focus on skills related to computation, code development, and statistics/data science workflows, including,\n\nopen science workflows and literate programming;\nintroduction to version control, Git and GitHub;\ncode style;\ndebugging;\ntesting;\ncollaboration with Git and GitHub;\nnumerical analysis (random number generation and floating point precision);\npackaging and reproducible environments; and\nautomated workflows.\n\n\n\n\nGoal 1: Emphasize good computational and code development practices (scripting, version control, testing, modularity, defensive programming, documentation, commenting, numerical analysis issues).\nGoal 2: Emphasize good practices for workflows, including reproducibility, automation, isolated environments.\nGoal 3: Provide practice with and introduce key tools for version control, testing, documentation, literate programming (documents with runnable code).",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "syllabus.html#about-the-computational-skills-workshop",
    "href": "syllabus.html#about-the-computational-skills-workshop",
    "title": "Overview",
    "section": "",
    "text": "The workshop will focus on skills related to computation, code development, and statistics/data science workflows, including,\n\nopen science workflows and literate programming;\nintroduction to version control, Git and GitHub;\ncode style;\ndebugging;\ntesting;\ncollaboration with Git and GitHub;\nnumerical analysis (random number generation and floating point precision);\npackaging and reproducible environments; and\nautomated workflows.\n\n\n\n\nGoal 1: Emphasize good computational and code development practices (scripting, version control, testing, modularity, defensive programming, documentation, commenting, numerical analysis issues).\nGoal 2: Emphasize good practices for workflows, including reproducibility, automation, isolated environments.\nGoal 3: Provide practice with and introduce key tools for version control, testing, documentation, literate programming (documents with runnable code).",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "syllabus.html#optional-introduction-to-computing-and-python",
    "href": "syllabus.html#optional-introduction-to-computing-and-python",
    "title": "Overview",
    "section": "(Optional) Introduction to Computing and Python",
    "text": "(Optional) Introduction to Computing and Python\nThe optional additional sessions (held Tuesday-Wednesday, August 20-21) provide a basic introduction to computing concepts (e.g., parts of a computer, ideas related to parallelization, introduction to the the shell/command line/terminal) and an introduction to Python.\nThese are intended for those with little experience (or wishing a refresher) with working in a command line context or with using Python, and are particularly important for those taking Statistics 243, which assumes basic knowledge of Python.\nThe introduction to Python will borrow heavily from this Software Carpentry Python lesson, with some additional topics added.",
    "crumbs": [
      "Overview"
    ]
  }
]